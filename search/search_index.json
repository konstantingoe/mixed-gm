{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"HUME: High-dimensional Undirected Mixed graph Estimation","text":"<p>This site contains the documentation for the <code>hume</code> Python package.</p>"},{"location":"#overview","title":"Overview","text":"<p>hume implements the methodology for learning sparse undirected graphical models from arbitrary mixed data (any combination of continuous and ordinal variables) presented in:</p> <p>G\u00f6bler, K., Drton, M., Mukherjee, S. and Miloschewski, A. (2024). High-dimensional undirected graphical models for arbitrary mixed data. Electronic Journal of Statistics, 18(1), 2339\u20132404. https://doi.org/10.1214/24-EJS2254</p> <p>Given a (high-dimensional) dataset with continuous and/or ordinal variables the package estimates the latent correlation matrix with pair-type-specific estimators and recovers the graph structure via graphical lasso with eBIC model selection.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Generate data from a latent sparse Gaussian model and binarise half the columns, then recover the graph.</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom hume import MixedGraphicalLasso\n\nrng = np.random.default_rng(0)\nn, d = 400, 20\n\n# --- Sparse precision matrix ------------------------------------------------\n# Start from the identity, add signal to ~12 randomly chosen pairs,\n# then enforce positive-definiteness via diagonal dominance.\nprecision = np.eye(d)\npairs = [(i, j) for i in range(d) for j in range(i + 1, d)]\ntrue_edges = set()\nfor idx in rng.choice(len(pairs), size=12, replace=False):\n    i, j = pairs[idx]\n    precision[i, j] = precision[j, i] = 0.5\n    true_edges.add(frozenset((f\"x{i}\", f\"x{j}\")))\nnp.fill_diagonal(precision, np.abs(precision).sum(axis=1) + 0.1)\n\n# --- Latent multivariate nonparanormal data ----------------------------------------\ncov = np.linalg.inv(precision)\nX = rng.multivariate_normal(np.zeros(d), cov, size=n)\nX = np.sign(X) * np.power(np.abs(X), 1.5)  # nonparanormal transform\n\n# --- Binarise first half of columns (probit / quantile transform) -----------\nn_bin = d // 2\np_bin = rng.uniform(0.4, 0.6, size=n_bin)\ndata = pd.DataFrame(X, columns=[f\"x{i}\" for i in range(d)])\nfor i in range(n_bin):\n    u = stats.norm.cdf(stats.zscore(X[:, i]))\n    data.iloc[:, i] = stats.binom.ppf(u, n=1, p=p_bin[i])\n\n# --- Fit the mixed graphical model ------------------------------------------\nmgl = MixedGraphicalLasso().fit(data)\n\nprint(f\"Selected alpha:  {mgl.alpha_:.4f}\")\nprint(f\"Number of edges: {mgl.n_edges_}\")\nprint(f\"Edges:           {mgl.graph_.edges}\")\n\n# --- Evaluation -------------------------------------------------------------\nrecovered = {frozenset(e) for e in mgl.graph_.edges}\ntp = len(true_edges &amp; recovered)\ntpr = tp / len(true_edges)\nfpr = (len(recovered) - tp) / (d * (d - 1) // 2 - len(true_edges))\nprint(f\"TPR: {tpr:.2f}  FPR: {fpr:.2f}\")\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install -e .\n</code></pre>"},{"location":"#main-api","title":"Main API","text":"Class / Function Description <code>MixedGraphicalLasso</code> Full pipeline: correlation \u2192 glasso path \u2192 eBIC selection \u2192 <code>UGRAPH</code> <code>SampleCorrelation</code> Latent correlation matrix for mixed data <code>omega_select</code> eBIC model selection over a glasso regularisation path <code>UGRAPH</code> Undirected graph class"},{"location":"#references","title":"References","text":"<ul> <li> <p>G\u00f6bler, K., Drton, M., Mukherjee, S. and Miloschewski, A. (2024).   High-dimensional undirected graphical models for arbitrary mixed data.   Electronic Journal of Statistics, 18(1), 2339\u20132404.   https://doi.org/10.1214/24-EJS2254</p> </li> <li> <p>Foygel, R. and Drton, M. (2010).   Extended Bayesian Information Criteria for Gaussian Graphical Models.   Advances in Neural Information Processing Systems, 23, 604\u2013612.</p> </li> <li> <p>Liu, H., Lafferty, J. and Wasserman, L. (2009).   The nonparanormal: Semi-parametric estimation of high dimensional undirected graphs.   Journal of Machine Learning Research, 10(80), 2295\u20132328.</p> </li> </ul> <p>See the API Reference for detailed documentation.</p>"},{"location":"reference/","title":"API Reference","text":"<p>This is the code documentation for the <code>hume</code> package, which implements the methodology from:</p> <p>G\u00f6bler, K., Drton, M., Mukherjee, S. and Miloschewski, A. (2024). High-dimensional undirected graphical models for arbitrary mixed data. Electronic Journal of Statistics, 18(1), 2339\u20132404. https://doi.org/10.1214/24-EJS2254</p>"},{"location":"reference/#main-classes","title":"Main Classes","text":"<p>Estimate a sample correlation matrix for mixed continuous/ordinal data.</p> <p>Pairwise correlations are estimated as follows:</p> <ul> <li>continuous - continuous: Spearman sin-transform   :math:<code>\\hat{\\sigma} = 2 \\sin(\\pi/6 \\cdot \\hat{\\rho}_S)</code>.</li> <li>continuous - ordinal: ad-hoc polyserial correlation via   :class:<code>~hume.correlation.PolyserialCorrelation</code>.</li> <li>ordinal - ordinal: maximum-likelihood polychoric correlation via   :class:<code>~hume.correlation.PolychoricCorrelation</code>.</li> </ul> <p>After calling :meth:<code>fit</code>, the estimated matrix is available as :attr:<code>correlation_matrix_</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n_levels_threshold</code> <code>int</code> <p>Columns with strictly fewer unique values are treated as ordinal.  Defaults to 20.</p> <code>20</code> <p>Example::</p> <pre><code>sc = SampleCorrelation().fit(X)\nprint(sc.correlation_matrix_)\n</code></pre> Source code in <code>hume/estimation.py</code> <pre><code>class SampleCorrelation:\n    r\"\"\"Estimate a sample correlation matrix for mixed continuous/ordinal data.\n\n    Pairwise correlations are estimated as follows:\n\n    * **continuous - continuous**: Spearman sin-transform\n      :math:`\\hat{\\sigma} = 2 \\sin(\\pi/6 \\cdot \\hat{\\rho}_S)`.\n    * **continuous - ordinal**: ad-hoc polyserial correlation via\n      :class:`~hume.correlation.PolyserialCorrelation`.\n    * **ordinal - ordinal**: maximum-likelihood polychoric correlation via\n      :class:`~hume.correlation.PolychoricCorrelation`.\n\n    After calling :meth:`fit`, the estimated matrix is available as\n    :attr:`correlation_matrix_`.\n\n    Args:\n        n_levels_threshold: Columns with strictly fewer unique values are\n            treated as ordinal.  Defaults to 20.\n\n    Example::\n\n        sc = SampleCorrelation().fit(X)\n        print(sc.correlation_matrix_)\n    \"\"\"\n\n    def __init__(\n        self,\n        n_levels_threshold: int = 20,\n    ) -&gt; None:\n        \"\"\"Construct a SampleCorrelation estimator.\n\n        Args:\n            n_levels_threshold: Unique-value threshold for ordinal detection.\n                Defaults to 20.\n        \"\"\"\n        self.n_levels_threshold = n_levels_threshold\n\n        # set after fit\n        self.correlation_matrix_: pd.DataFrame | None = None\n        self.feature_names_: list[str] | None = None\n\n    # ------------------------------------------------------------------\n    # Public API\n    # ------------------------------------------------------------------\n\n    def fit(self, x: pd.DataFrame | NDArray[Any]) -&gt; SampleCorrelation:\n        \"\"\"Estimate the correlation matrix from *x*.\n\n        Args:\n            x: Data matrix of shape ``(n_samples, n_features)``.\n                A :class:`pandas.DataFrame` is preferred so that column names\n                are preserved; a 2-D :class:`numpy.ndarray` is also accepted.\n\n        Returns:\n            *self* -- enables method chaining.\n\n        Raises:\n            ValueError: If *x* has fewer than 2 columns.\n        \"\"\"\n        df = x if isinstance(x, pd.DataFrame) else pd.DataFrame(x)\n        if df.shape[1] &lt; 2:\n            raise ValueError(\"X must have at least 2 columns.\")\n\n        self.feature_names_ = list(df.columns.astype(str))\n\n        rho = self._estimate(df)\n\n        _check_correlation_bounds(rho)\n        self.correlation_matrix_ = pd.DataFrame(rho, index=self.feature_names_, columns=self.feature_names_)\n        return self\n\n    # ------------------------------------------------------------------\n    # Internals\n    # ------------------------------------------------------------------\n\n    def _is_discrete(self, df: pd.DataFrame) -&gt; NDArray[np.bool_]:\n        return np.array([df.iloc[:, j].nunique() &lt; self.n_levels_threshold for j in range(df.shape[1])])\n\n    def _estimate(self, df: pd.DataFrame) -&gt; NDArray[Any]:\n        r\"\"\"Estimate pairwise correlations under the latent Gaussian copula.\n\n        Rules per pair type:\n\n        * **cont - cont**: :math:`2 \\sin(\\pi/6 \\cdot \\hat{\\rho}_S)` where\n            :math:`\\hat{\\rho}_S` is Spearman's rank correlation.\n        * **cont - ord**: ad-hoc polyserial via :class:`PolyserialCorrelation`.\n        * **ord - ord**: MLE polychoric via :class:`PolychoricCorrelation`.\n        \"\"\"\n        d = df.shape[1]\n        rho = np.eye(d)\n        disc = self._is_discrete(df)\n\n        for i in range(d - 1):\n            for j in range(i + 1, d):\n                xi = df.iloc[:, i].to_numpy(dtype=float)\n                xj = df.iloc[:, j].to_numpy(dtype=float)\n\n                if not disc[i] and not disc[j]:\n                    rho_s = float(stats.spearmanr(xi, xj)[0])  # pyright: ignore[reportArgumentType]\n                    r = 2.0 * np.sin(np.pi / 6.0 * rho_s)\n                elif disc[i] and disc[j]:\n                    r = PolychoricCorrelation().fit(xi, xj).correlation\n                else:\n                    r = PolyserialCorrelation(n_levels_threshold=self.n_levels_threshold).fit(xi, xj).correlation\n\n                rho[i, j] = rho[j, i] = r\n\n        return rho\n</code></pre> <p>Sparse Gaussian graphical model for mixed continuous/ordinal data.</p> <p>Estimates a precision matrix and the associated :class:<code>~hume.graphs.UGRAPH</code> by:</p> <ol> <li>Computing the sample correlation matrix via :class:<code>SampleCorrelation</code>.</li> <li>Projecting to the positive-definite cone if necessary.</li> <li>Computing the full graphical lasso regularisation path.</li> <li>Selecting the model with the smallest eBIC via :func:<code>omega_select</code>.</li> <li>Re-fitting graphical lasso at the selected alpha for a clean final solution.</li> </ol> <p>The overall design mirrors <code>sklearn.covariance.GraphicalLassoCV</code> but replaces cross-validation with eBIC-based selection.</p> <p>Parameters:</p> Name Type Description Default <code>n_lambdas</code> <code>int</code> <p>Number of regularisation steps in the path.  Defaults to 50.</p> <code>50</code> <code>ebic_gamma</code> <code>float</code> <p>eBIC hyper-parameter :math:<code>\\gamma</code>.  <code>0</code> gives standard BIC; larger values impose a stronger dimensionality penalty. Defaults to 0.1.</p> <code>0.1</code> <code>n_levels_threshold</code> <code>int</code> <p>Unique-value threshold for declaring a column ordinal.  Defaults to 20.</p> <code>20</code> <p>Attributes set after :meth:<code>fit</code>:     precision_matrix_ (pd.DataFrame): Partial correlation matrix derived         from the estimated precision (diagonal = 1).     correlation_matrix_ (pd.DataFrame): Sample correlation matrix used as         input to graphical lasso.     graph_ (UGRAPH): Undirected graph whose edges correspond to non-zero         off-diagonal entries in precision_matrix_.     alpha_ (float): Selected regularisation parameter.     ebic_scores_ (np.ndarray): eBIC values for each point on the path.     singular_ (bool): Whether positive-definite projection was needed.     feature_names_ (list[str]): Variable names inferred from the input.</p> <p>Example::</p> <pre><code>mgl = MixedGraphicalLasso(ebic_gamma=0.1)\nmgl.fit(X)\nprint(mgl.graph_.edges)\nprint(mgl.precision_matrix_)\n</code></pre> Source code in <code>hume/estimation.py</code> <pre><code>class MixedGraphicalLasso:\n    r\"\"\"Sparse Gaussian graphical model for mixed continuous/ordinal data.\n\n    Estimates a precision matrix and the associated :class:`~hume.graphs.UGRAPH`\n    by:\n\n    1. Computing the sample correlation matrix via :class:`SampleCorrelation`.\n    2. Projecting to the positive-definite cone if necessary.\n    3. Computing the full graphical lasso regularisation path.\n    4. Selecting the model with the smallest eBIC via :func:`omega_select`.\n    5. Re-fitting graphical lasso at the selected alpha for a clean final solution.\n\n    The overall design mirrors ``sklearn.covariance.GraphicalLassoCV`` but\n    replaces cross-validation with eBIC-based selection.\n\n    Args:\n        n_lambdas: Number of regularisation steps in the path.  Defaults to 50.\n        ebic_gamma: eBIC hyper-parameter :math:`\\gamma`.  ``0`` gives standard\n            BIC; larger values impose a stronger dimensionality penalty.\n            Defaults to 0.1.\n        n_levels_threshold: Unique-value threshold for declaring a column\n            ordinal.  Defaults to 20.\n\n    Attributes set after :meth:`fit`:\n        precision_matrix_ (pd.DataFrame): Partial correlation matrix derived\n            from the estimated precision (diagonal = 1).\n        correlation_matrix_ (pd.DataFrame): Sample correlation matrix used as\n            input to graphical lasso.\n        graph_ (UGRAPH): Undirected graph whose edges correspond to non-zero\n            off-diagonal entries in *precision_matrix_*.\n        alpha_ (float): Selected regularisation parameter.\n        ebic_scores_ (np.ndarray): eBIC values for each point on the path.\n        singular_ (bool): Whether positive-definite projection was needed.\n        feature_names_ (list[str]): Variable names inferred from the input.\n\n    Example::\n\n        mgl = MixedGraphicalLasso(ebic_gamma=0.1)\n        mgl.fit(X)\n        print(mgl.graph_.edges)\n        print(mgl.precision_matrix_)\n    \"\"\"\n\n    def __init__(\n        self,\n        n_lambdas: int = 50,\n        ebic_gamma: float = 0.1,\n        n_levels_threshold: int = 20,\n    ) -&gt; None:\n        \"\"\"Construct a MixedGraphicalLasso estimator.\n\n        Args:\n            n_lambdas: Length of the regularisation path.  Defaults to 50.\n            ebic_gamma: eBIC dimensionality penalty weight in [0, 1].\n                Defaults to 0.1.\n            n_levels_threshold: Ordinal detection threshold.  Defaults to 20.\n\n        Raises:\n            ValueError: If *ebic_gamma* is not in [0, 1].\n        \"\"\"\n        if not (0.0 &lt;= ebic_gamma &lt;= 1.0):\n            raise ValueError(f\"`ebic_gamma` must be in [0, 1], got {ebic_gamma}.\")\n\n        self.n_lambdas = n_lambdas\n        self.ebic_gamma = ebic_gamma\n        self.n_levels_threshold = n_levels_threshold\n\n        # set after fit\n        self.precision_matrix_: pd.DataFrame | None = None\n        self.correlation_matrix_: pd.DataFrame | None = None\n        self.graph_: UGRAPH | None = None\n        self.alpha_: float | None = None\n        self.ebic_scores_: NDArray[Any] | None = None\n        self.singular_: bool | None = None\n        self.feature_names_: list[str] | None = None\n\n    # ------------------------------------------------------------------\n    # Public API\n    # ------------------------------------------------------------------\n\n    def fit(self, x: pd.DataFrame | NDArray[Any]) -&gt; MixedGraphicalLasso:\n        \"\"\"Fit the model to *x*.\n\n        Args:\n            x: Data matrix of shape ``(n_samples, n_features)``.\n                A :class:`pandas.DataFrame` with named columns is preferred.\n\n        Returns:\n            *self* -- enables method chaining.\n        \"\"\"\n        df = x if isinstance(x, pd.DataFrame) else pd.DataFrame(x)\n        n, _ = df.shape\n\n        # ----------------------------------------------------------------\n        # Step 1 -- sample correlation\n        # ----------------------------------------------------------------\n        sc = SampleCorrelation(\n            n_levels_threshold=self.n_levels_threshold,\n        ).fit(df)\n\n        self.feature_names_ = sc.feature_names_\n        rho_raw: NDArray[Any] = sc.correlation_matrix_.to_numpy()  # type: ignore[union-attr]\n\n        # ----------------------------------------------------------------\n        # Step 2 -- ensure positive definiteness\n        # ----------------------------------------------------------------\n        rho, singular = _make_positive_definite(rho_raw, keep_diag=True)\n        self.singular_ = singular\n        self.correlation_matrix_ = pd.DataFrame(rho, index=self.feature_names_, columns=self.feature_names_)\n\n        # ----------------------------------------------------------------\n        # Step 3 -- regularisation path\n        # ----------------------------------------------------------------\n        precision_path, lambda_path = _glasso_path(rho, n_lambdas=self.n_lambdas)\n\n        # ----------------------------------------------------------------\n        # Step 4 -- eBIC model selection\n        # ----------------------------------------------------------------\n        _, selected_alpha, ebic_scores = omega_select(\n            precision_path,\n            lambda_path,\n            n=n,\n            s=rho,\n            gamma=self.ebic_gamma,\n        )\n        self.alpha_ = selected_alpha\n        self.ebic_scores_ = ebic_scores\n\n        # ----------------------------------------------------------------\n        # Step 5 -- final fit at selected alpha\n        # ----------------------------------------------------------------\n        try:\n            _, omega_final = graphical_lasso(rho, alpha=selected_alpha, mode=\"cd\", max_iter=200)\n        except (FloatingPointError, ValueError):\n            logger.warning(\n                \"Final graphical_lasso fit failed for alpha=%.4f; falling back to path estimate.\",\n                selected_alpha,\n            )\n            best_idx = int(np.argmin(ebic_scores))\n            omega_final = precision_path[best_idx]\n\n        omega_pcor = _precision_to_partial(omega_final)\n\n        # ----------------------------------------------------------------\n        # Store results\n        # ----------------------------------------------------------------\n        names = self.feature_names_\n        assert names is not None  # guaranteed by SampleCorrelation.fit\n        self.precision_matrix_ = pd.DataFrame(omega_pcor, index=names, columns=names)\n        self.graph_ = self._build_ugraph(omega_pcor, names)\n\n        return self\n\n    @property\n    def n_edges_(self) -&gt; int:\n        \"\"\"Number of edges in the estimated graph.\n\n        Raises:\n            RuntimeError: If :meth:`fit` has not been called.\n        \"\"\"\n        if self.graph_ is None:\n            raise RuntimeError(\"Call .fit() before accessing n_edges_.\")\n        return self.graph_.num_edges\n\n    # ------------------------------------------------------------------\n    # Internals\n    # ------------------------------------------------------------------\n\n    @staticmethod\n    def _build_ugraph(pcor: NDArray[Any], names: list[str]) -&gt; UGRAPH:\n        \"\"\"Construct a UGRAPH from a partial correlation matrix.\n\n        An edge ``(i, j)`` is included whenever ``pcor[i, j] != 0``.\n\n        Args:\n            pcor: Partial correlation matrix (diagonal = 1).\n            names: Variable names corresponding to rows/columns.\n\n        Returns:\n            UGRAPH with one node per variable and one undirected edge per\n            non-zero off-diagonal entry.\n        \"\"\"\n        d = pcor.shape[0]\n        edges: list[tuple[str, str]] = [\n            (names[i], names[j]) for i in range(d - 1) for j in range(i + 1, d) if pcor[i, j] != 0.0\n        ]\n        return UGRAPH(nodes=names, edges=edges)\n</code></pre>"},{"location":"reference/#hume.estimation.SampleCorrelation.__init__","title":"<code>__init__(n_levels_threshold=20)</code>","text":"<p>Construct a SampleCorrelation estimator.</p> <p>Parameters:</p> Name Type Description Default <code>n_levels_threshold</code> <code>int</code> <p>Unique-value threshold for ordinal detection. Defaults to 20.</p> <code>20</code> Source code in <code>hume/estimation.py</code> <pre><code>def __init__(\n    self,\n    n_levels_threshold: int = 20,\n) -&gt; None:\n    \"\"\"Construct a SampleCorrelation estimator.\n\n    Args:\n        n_levels_threshold: Unique-value threshold for ordinal detection.\n            Defaults to 20.\n    \"\"\"\n    self.n_levels_threshold = n_levels_threshold\n\n    # set after fit\n    self.correlation_matrix_: pd.DataFrame | None = None\n    self.feature_names_: list[str] | None = None\n</code></pre>"},{"location":"reference/#hume.estimation.SampleCorrelation.fit","title":"<code>fit(x)</code>","text":"<p>Estimate the correlation matrix from x.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataFrame | NDArray[Any]</code> <p>Data matrix of shape <code>(n_samples, n_features)</code>. A :class:<code>pandas.DataFrame</code> is preferred so that column names are preserved; a 2-D :class:<code>numpy.ndarray</code> is also accepted.</p> required <p>Returns:</p> Type Description <code>SampleCorrelation</code> <p>self -- enables method chaining.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If x has fewer than 2 columns.</p> Source code in <code>hume/estimation.py</code> <pre><code>def fit(self, x: pd.DataFrame | NDArray[Any]) -&gt; SampleCorrelation:\n    \"\"\"Estimate the correlation matrix from *x*.\n\n    Args:\n        x: Data matrix of shape ``(n_samples, n_features)``.\n            A :class:`pandas.DataFrame` is preferred so that column names\n            are preserved; a 2-D :class:`numpy.ndarray` is also accepted.\n\n    Returns:\n        *self* -- enables method chaining.\n\n    Raises:\n        ValueError: If *x* has fewer than 2 columns.\n    \"\"\"\n    df = x if isinstance(x, pd.DataFrame) else pd.DataFrame(x)\n    if df.shape[1] &lt; 2:\n        raise ValueError(\"X must have at least 2 columns.\")\n\n    self.feature_names_ = list(df.columns.astype(str))\n\n    rho = self._estimate(df)\n\n    _check_correlation_bounds(rho)\n    self.correlation_matrix_ = pd.DataFrame(rho, index=self.feature_names_, columns=self.feature_names_)\n    return self\n</code></pre>"},{"location":"reference/#hume.estimation.MixedGraphicalLasso.n_edges_","title":"<code>n_edges_</code>  <code>property</code>","text":"<p>Number of edges in the estimated graph.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If :meth:<code>fit</code> has not been called.</p>"},{"location":"reference/#hume.estimation.MixedGraphicalLasso.__init__","title":"<code>__init__(n_lambdas=50, ebic_gamma=0.1, n_levels_threshold=20)</code>","text":"<p>Construct a MixedGraphicalLasso estimator.</p> <p>Parameters:</p> Name Type Description Default <code>n_lambdas</code> <code>int</code> <p>Length of the regularisation path.  Defaults to 50.</p> <code>50</code> <code>ebic_gamma</code> <code>float</code> <p>eBIC dimensionality penalty weight in [0, 1]. Defaults to 0.1.</p> <code>0.1</code> <code>n_levels_threshold</code> <code>int</code> <p>Ordinal detection threshold.  Defaults to 20.</p> <code>20</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If ebic_gamma is not in [0, 1].</p> Source code in <code>hume/estimation.py</code> <pre><code>def __init__(\n    self,\n    n_lambdas: int = 50,\n    ebic_gamma: float = 0.1,\n    n_levels_threshold: int = 20,\n) -&gt; None:\n    \"\"\"Construct a MixedGraphicalLasso estimator.\n\n    Args:\n        n_lambdas: Length of the regularisation path.  Defaults to 50.\n        ebic_gamma: eBIC dimensionality penalty weight in [0, 1].\n            Defaults to 0.1.\n        n_levels_threshold: Ordinal detection threshold.  Defaults to 20.\n\n    Raises:\n        ValueError: If *ebic_gamma* is not in [0, 1].\n    \"\"\"\n    if not (0.0 &lt;= ebic_gamma &lt;= 1.0):\n        raise ValueError(f\"`ebic_gamma` must be in [0, 1], got {ebic_gamma}.\")\n\n    self.n_lambdas = n_lambdas\n    self.ebic_gamma = ebic_gamma\n    self.n_levels_threshold = n_levels_threshold\n\n    # set after fit\n    self.precision_matrix_: pd.DataFrame | None = None\n    self.correlation_matrix_: pd.DataFrame | None = None\n    self.graph_: UGRAPH | None = None\n    self.alpha_: float | None = None\n    self.ebic_scores_: NDArray[Any] | None = None\n    self.singular_: bool | None = None\n    self.feature_names_: list[str] | None = None\n</code></pre>"},{"location":"reference/#hume.estimation.MixedGraphicalLasso.fit","title":"<code>fit(x)</code>","text":"<p>Fit the model to x.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>DataFrame | NDArray[Any]</code> <p>Data matrix of shape <code>(n_samples, n_features)</code>. A :class:<code>pandas.DataFrame</code> with named columns is preferred.</p> required <p>Returns:</p> Type Description <code>MixedGraphicalLasso</code> <p>self -- enables method chaining.</p> Source code in <code>hume/estimation.py</code> <pre><code>def fit(self, x: pd.DataFrame | NDArray[Any]) -&gt; MixedGraphicalLasso:\n    \"\"\"Fit the model to *x*.\n\n    Args:\n        x: Data matrix of shape ``(n_samples, n_features)``.\n            A :class:`pandas.DataFrame` with named columns is preferred.\n\n    Returns:\n        *self* -- enables method chaining.\n    \"\"\"\n    df = x if isinstance(x, pd.DataFrame) else pd.DataFrame(x)\n    n, _ = df.shape\n\n    # ----------------------------------------------------------------\n    # Step 1 -- sample correlation\n    # ----------------------------------------------------------------\n    sc = SampleCorrelation(\n        n_levels_threshold=self.n_levels_threshold,\n    ).fit(df)\n\n    self.feature_names_ = sc.feature_names_\n    rho_raw: NDArray[Any] = sc.correlation_matrix_.to_numpy()  # type: ignore[union-attr]\n\n    # ----------------------------------------------------------------\n    # Step 2 -- ensure positive definiteness\n    # ----------------------------------------------------------------\n    rho, singular = _make_positive_definite(rho_raw, keep_diag=True)\n    self.singular_ = singular\n    self.correlation_matrix_ = pd.DataFrame(rho, index=self.feature_names_, columns=self.feature_names_)\n\n    # ----------------------------------------------------------------\n    # Step 3 -- regularisation path\n    # ----------------------------------------------------------------\n    precision_path, lambda_path = _glasso_path(rho, n_lambdas=self.n_lambdas)\n\n    # ----------------------------------------------------------------\n    # Step 4 -- eBIC model selection\n    # ----------------------------------------------------------------\n    _, selected_alpha, ebic_scores = omega_select(\n        precision_path,\n        lambda_path,\n        n=n,\n        s=rho,\n        gamma=self.ebic_gamma,\n    )\n    self.alpha_ = selected_alpha\n    self.ebic_scores_ = ebic_scores\n\n    # ----------------------------------------------------------------\n    # Step 5 -- final fit at selected alpha\n    # ----------------------------------------------------------------\n    try:\n        _, omega_final = graphical_lasso(rho, alpha=selected_alpha, mode=\"cd\", max_iter=200)\n    except (FloatingPointError, ValueError):\n        logger.warning(\n            \"Final graphical_lasso fit failed for alpha=%.4f; falling back to path estimate.\",\n            selected_alpha,\n        )\n        best_idx = int(np.argmin(ebic_scores))\n        omega_final = precision_path[best_idx]\n\n    omega_pcor = _precision_to_partial(omega_final)\n\n    # ----------------------------------------------------------------\n    # Store results\n    # ----------------------------------------------------------------\n    names = self.feature_names_\n    assert names is not None  # guaranteed by SampleCorrelation.fit\n    self.precision_matrix_ = pd.DataFrame(omega_pcor, index=names, columns=names)\n    self.graph_ = self._build_ugraph(omega_pcor, names)\n\n    return self\n</code></pre>"},{"location":"reference/#model-selection","title":"Model Selection","text":"<p>Select the best precision matrix from a glasso path using eBIC.</p> <p>The extended BIC criterion is:</p> <p>.. math::</p> <pre><code>\\mathrm{eBIC}(\\Omega) =\n    -2 \\ell(\\Omega \\mid E)\n    + |E| \\log n\n    + 4 \\gamma |E| \\log d\n</code></pre> <p>where :math:<code>|E|</code> is the number of edges, :math:<code>n</code> the sample size, :math:<code>d</code> the number of variables, and :math:<code>\\gamma \\in [0,1]</code> an additional penalty for high-dimensional settings.</p> <p>Parameters:</p> Name Type Description Default <code>precision_path</code> <code>list[NDArray[Any]]</code> <p>List of precision matrices along the regularisation path.</p> required <code>lambda_path</code> <code>NDArray[Any]</code> <p>Corresponding array of <code>alpha</code> values (same length).</p> required <code>n</code> <code>int</code> <p>Sample size.</p> required <code>s</code> <code>NDArray[Any]</code> <p>Sample correlation/covariance matrix used for estimation.</p> required <code>gamma</code> <code>float</code> <p>eBIC hyper-parameter.  <code>0</code> recovers standard BIC. Defaults to 0.1.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>NDArray[Any]</code> <p>Tuple <code>(selected_precision, selected_alpha, ebic_scores)</code> where</p> <code>float</code> <p>selected_precision is the raw precision matrix for the chosen model,</p> <code>NDArray[Any]</code> <p>selected_alpha is the corresponding regularisation value, and</p> <code>tuple[NDArray[Any], float, NDArray[Any]]</code> <p>ebic_scores is the full eBIC array along the path.</p> References <p>Foygel, Rina and Drton, Mathias. (2010). Extended Bayesian Information Criteria for Gaussian Graphical Models. Advances in Neural Information Processing Systems, Volume 23, pp. 604-612.</p> Source code in <code>hume/estimation.py</code> <pre><code>def omega_select(\n    precision_path: list[NDArray[Any]],\n    lambda_path: NDArray[Any],\n    n: int,\n    s: NDArray[Any],\n    *,\n    gamma: float = 0.1,\n) -&gt; tuple[NDArray[Any], float, NDArray[Any]]:\n    r\"\"\"Select the best precision matrix from a glasso path using eBIC.\n\n    The extended BIC criterion is:\n\n    .. math::\n\n        \\mathrm{eBIC}(\\Omega) =\n            -2 \\ell(\\Omega \\mid E)\n            + |E| \\log n\n            + 4 \\gamma |E| \\log d\n\n    where :math:`|E|` is the number of edges, :math:`n` the sample size,\n    :math:`d` the number of variables, and :math:`\\gamma \\in [0,1]` an\n    additional penalty for high-dimensional settings.\n\n    Args:\n        precision_path: List of precision matrices along the regularisation path.\n        lambda_path: Corresponding array of ``alpha`` values (same length).\n        n: Sample size.\n        s: Sample correlation/covariance matrix used for estimation.\n        gamma: eBIC hyper-parameter.  ``0`` recovers standard BIC.\n            Defaults to 0.1.\n\n    Returns:\n        Tuple ``(selected_precision, selected_alpha, ebic_scores)`` where\n        *selected_precision* is the raw precision matrix for the chosen model,\n        *selected_alpha* is the corresponding regularisation value, and\n        *ebic_scores* is the full eBIC array along the path.\n\n    References:\n        Foygel, Rina and Drton, Mathias. (2010).\n        Extended Bayesian Information Criteria for Gaussian Graphical Models.\n        Advances in Neural Information Processing Systems, Volume 23, pp. 604-612.\n    \"\"\"\n    d = s.shape[0]\n    ebic = np.zeros(len(lambda_path))\n\n    for k, omega in enumerate(precision_path):\n        n_edges = _edgenumber(omega)\n        sign, logdet = np.linalg.slogdet(omega)\n        logdet = logdet if sign &gt; 0 else -np.inf\n        loglik = 0.5 * n * (logdet - np.trace(s @ omega))\n        ebic[k] = -2 * loglik + n_edges * np.log(n) + 4 * gamma * n_edges * np.log(d)\n\n    best = int(np.argmin(ebic))\n    return precision_path[best].copy(), float(lambda_path[best]), ebic\n</code></pre>"},{"location":"reference/#graph-classes","title":"Graph Classes","text":"<p>               Bases: <code>GRAPH</code></p> <p>Class for dealing with undirected graph i.e. graphs that only contain undirected edges.</p> Source code in <code>hume/graphs.py</code> <pre><code>class UGRAPH(GRAPH):\n    \"\"\"Class for dealing with undirected graph i.e. graphs that only contain undirected edges.\"\"\"\n\n    def __init__(\n        self,\n        nodes: list[str] | None = None,\n        edges: list[tuple[str, str]] | None = None,\n    ) -&gt; None:\n        \"\"\"UGRAPH constructor.\n\n        Args:\n            nodes (list[str] | None, optional): Nodes. Defaults to None.\n            edges (list[tuple[str,str]] | None, optional): Edges. Defaults to None.\n        \"\"\"\n        if nodes is None:\n            nodes = []\n        if edges is None:\n            edges = []\n\n        self._nodes: set[str] = set(nodes)\n        self._edges: set[tuple[str, str]] = set()\n        self._neighbors: defaultdict[str, set[str]] = defaultdict(set)\n\n        for edge in edges:\n            self._add_edge(*edge)\n\n    def _add_edge(self, i: str, j: str) -&gt; None:\n        self._nodes.add(i)\n        self._nodes.add(j)\n        self._edges.add((i, j))\n\n        self._neighbors[i].add(j)\n        self._neighbors[j].add(i)\n\n    def neighbors(self, node: str) -&gt; set[str]:\n        \"\"\"Gives all neighbors of node `node`.\n\n        Args:\n            node (str): node in current UGRAPH.\n\n        Returns:\n            set: set of neighbors.\n        \"\"\"\n        if node in self._neighbors:\n            return self._neighbors[node]\n        else:\n            return set()\n\n    def is_adjacent(self, i: str, j: str) -&gt; bool:\n        \"\"\"Return True if the graph contains an undirected edge between i and j.\n\n        Args:\n            i (str): node i.\n            j (str): node j.\n\n        Returns:\n            bool: True if i - j\n        \"\"\"\n        return (i, j) in self._edges or (j, i) in self._edges\n\n    def is_clique(self, potential_clique: set[str]) -&gt; bool:\n        \"\"\"Check every pair of nodes in potential_clique is adjacent.\"\"\"\n        return all(self.is_adjacent(i, j) for i, j in combinations(potential_clique, 2))\n\n    @classmethod\n    def from_pandas_adjacency(cls, pd_amat: pd.DataFrame) -&gt; UGRAPH:\n        \"\"\"Build UGRAPH from a Pandas adjacency matrix.\n\n        Args:\n            pd_amat (pd.DataFrame): input adjacency matrix.\n\n        Returns:\n            UGRAPH\n        \"\"\"\n        assert pd_amat.shape[0] == pd_amat.shape[1]\n        nodes = list(pd_amat.columns)\n\n        all_connections = []\n        start, end = np.where(pd_amat != 0)\n        for idx, _ in enumerate(start):\n            all_connections.append((pd_amat.columns[start[idx]], pd_amat.columns[end[idx]]))\n\n        edges = [tuple(item) for item in set(frozenset(item) for item in all_connections)]\n\n        return UGRAPH(nodes=nodes, edges=edges)\n\n    def remove_edge(self, i: str, j: str) -&gt; None:\n        \"\"\"Removes edge in question.\n\n        Args:\n            i (str): first node\n            j (str): second node\n\n        Raises:\n            AssertionError: if edge does not exist\n        \"\"\"\n        if not self.is_adjacent(i, j):\n            raise AssertionError(\"Edge does not exist in current UGRAPH\")\n\n        self._edges.discard((i, j))\n        self._edges.discard((j, i))\n        self._neighbors[i].discard(j)\n        self._neighbors[j].discard(i)\n\n    def remove_node(self, node: str) -&gt; None:\n        \"\"\"Remove a node from the graph.\n\n        Args:\n            node (str): node to remove\n        \"\"\"\n        self._nodes.remove(node)\n\n        self._edges = {(i, j) for i, j in self._edges if node not in {i, j}}\n\n        for nbr in self._neighbors[node]:\n            self._neighbors[nbr].discard(node)\n\n        self._neighbors.pop(node, \"I was never here\")\n\n    @property\n    def adjacency_matrix(self) -&gt; pd.DataFrame:\n        \"\"\"Returns adjacency matrix.\n\n        The i,jth entry being one indicates that there is an undirected edge\n        between i and j. A zero indicates that there is no edge. The matrix\n        is symmetric.\n\n        Returns:\n            pd.DataFrame: adjacency matrix\n        \"\"\"\n        amat = pd.DataFrame(\n            np.zeros([self.num_nodes, self.num_nodes]),\n            index=self.nodes,\n            columns=self.nodes,\n        )\n        for edge in self.edges:\n            amat.loc[edge] = amat.loc[edge[::-1]] = 1\n        return amat\n\n    @property\n    def causal_order(self) -&gt; None:\n        \"\"\"Causal order is None.\n\n        This is because undirected graphs do not imply a causal order.\n\n        Returns:\n            None: None\n        \"\"\"\n        return None\n\n    def copy(self) -&gt; UGRAPH:\n        \"\"\"Return a copy of the graph.\"\"\"\n        return UGRAPH(nodes=list(self._nodes), edges=list(self._edges))\n\n    def show(self) -&gt; None:\n        \"\"\"Plot UGRAPH.\"\"\"\n        graph = self.to_networkx()\n        pos = nx.circular_layout(graph)\n        nx.draw(graph, pos=pos, with_labels=True)\n\n    def to_networkx(self) -&gt; nx.Graph:\n        \"\"\"Convert to networkx graph.\n\n        Returns:\n            nx.Graph: Undirected networkx graph.\n        \"\"\"\n        nx_ugraph = nx.Graph()\n        nx_ugraph.add_nodes_from(self.nodes)\n        nx_ugraph.add_edges_from(self.edges)\n        return nx_ugraph\n\n    @property\n    def nodes(self) -&gt; list[str]:\n        \"\"\"Get all nodes in current UGRAPH.\n\n        Returns:\n            list: list of nodes.\n        \"\"\"\n        return sorted(list(self._nodes))\n\n    @property\n    def num_nodes(self) -&gt; int:\n        \"\"\"Number of nodes in current UGRAPH.\n\n        Returns:\n            int: Number of nodes\n        \"\"\"\n        return len(self._nodes)\n\n    @property\n    def num_edges(self) -&gt; int:\n        \"\"\"Number of edges in current UGRAPH.\n\n        Returns:\n            int: Number of edges\n        \"\"\"\n        return len(self._edges)\n\n    @property\n    def edges(self) -&gt; list[tuple[str, str]]:\n        \"\"\"Gives all edges in current UGRAPH.\n\n        Returns:\n            list[tuple[str,str]]: List of edges.\n        \"\"\"\n        return list(self._edges)\n</code></pre> <p>               Bases: <code>GRAPH</code></p> <p>Class for dealing with partially directed graph i.e.</p> <p>graphs that contain both directed and undirected edges.</p> Source code in <code>hume/graphs.py</code> <pre><code>class PDAG(GRAPH):\n    \"\"\"Class for dealing with partially directed graph i.e.\n\n    graphs that contain both directed and undirected edges.\n    \"\"\"\n\n    def __init__(\n        self,\n        nodes: list[str] | None = None,\n        dir_edges: list[tuple[str, str]] | None = None,\n        undir_edges: list[tuple[str, str]] | None = None,\n    ) -&gt; None:\n        \"\"\"PDAG constructor.\n\n        Args:\n            nodes (list[str] | None, optional): Nodes in the PDAG. Defaults to None.\n            dir_edges (list[tuple[str,str]] | None, optional): directed edges. Defaults to None.\n            undir_edges (list[tuple[str,str]] | None, optional): undirected edges. Defaults to None.\n        \"\"\"\n        if nodes is None:\n            nodes = []\n        if dir_edges is None:\n            dir_edges = []\n        if undir_edges is None:\n            undir_edges = []\n\n        self._nodes = set(nodes)\n        self._undir_edges: set[tuple[str, str]] = set()\n        self._dir_edges: set[tuple[str, str]] = set()\n        self._parents: defaultdict[str, set[str]] = defaultdict(set)\n        self._children: defaultdict[str, set[str]] = defaultdict(set)\n        self._neighbors: defaultdict[str, set[str]] = defaultdict(set)\n        self._undirected_neighbors: defaultdict[str, set[str]] = defaultdict(set)\n        self.random_state: np.random.Generator = np.random.default_rng(seed=2026)\n\n        for dir_edge in dir_edges:\n            self._add_dir_edge(*dir_edge)\n        for unir_edge in undir_edges:\n            self._add_undir_edge(*unir_edge)\n\n    def _add_dir_edge(self, i: str, j: str) -&gt; None:\n        self._nodes.add(i)\n        self._nodes.add(j)\n        self._dir_edges.add((i, j))\n\n        self._neighbors[i].add(j)\n        self._neighbors[j].add(i)\n\n        self._children[i].add(j)\n        self._parents[j].add(i)\n\n    def _add_undir_edge(self, i: str, j: str) -&gt; None:\n        self._nodes.add(i)\n        self._nodes.add(j)\n        self._undir_edges.add((i, j))\n\n        self._neighbors[i].add(j)\n        self._neighbors[j].add(i)\n\n        self._undirected_neighbors[i].add(j)\n        self._undirected_neighbors[j].add(i)\n\n    def children(self, node: str) -&gt; set[str]:\n        \"\"\"Gives all children of node `node`.\n\n        Args:\n            node (str): node in current PDAG.\n\n        Returns:\n            set: set of children.\n        \"\"\"\n        if node in self._children:\n            return self._children[node]\n        else:\n            return set()\n\n    def parents(self, node: str) -&gt; set[str]:\n        \"\"\"Gives all parents of node `node`.\n\n        Args:\n            node (str): node in current PDAG.\n\n        Returns:\n            set: set of parents.\n        \"\"\"\n        if node in self._parents:\n            return self._parents[node]\n        else:\n            return set()\n\n    def neighbors(self, node: str) -&gt; set[str]:\n        \"\"\"Gives all neighbors of node `node`.\n\n        Args:\n            node (str): node in current PDAG.\n\n        Returns:\n            set: set of neighbors.\n        \"\"\"\n        if node in self._neighbors:\n            return self._neighbors[node]\n        else:\n            return set()\n\n    def undir_neighbors(self, node: str) -&gt; set[str]:\n        \"\"\"Gives all undirected neighbors of node `node`.\n\n        Args:\n            node (str): node in current PDAG.\n\n        Returns:\n            set: set of undirected neighbors.\n        \"\"\"\n        if node in self._undirected_neighbors:\n            return self._undirected_neighbors[node]\n        else:\n            return set()\n\n    def is_adjacent(self, i: str, j: str) -&gt; bool:\n        \"\"\"Return True if the graph contains an directed or undirected edge between i and j.\n\n        Args:\n            i (str): node i.\n            j (str): node j.\n\n        Returns:\n            bool: True if i-j or i-&gt;j or i&lt;-j\n        \"\"\"\n        return any((\n            (j, i) in self.dir_edges or (j, i) in self.undir_edges,\n            (i, j) in self.dir_edges or (i, j) in self.undir_edges,\n        ))\n\n    def is_clique(self, potential_clique: set[str]) -&gt; bool:\n        \"\"\"Check every pair of node X potential_clique is adjacent.\"\"\"\n        return all(self.is_adjacent(i, j) for i, j in combinations(potential_clique, 2))\n\n    @classmethod\n    def from_pandas_adjacency(cls, pd_amat: pd.DataFrame) -&gt; PDAG:\n        \"\"\"Build PDAG from a Pandas adjacency matrix.\n\n        Args:\n            pd_amat (pd.DataFrame): input adjacency matrix.\n\n        Returns:\n            PDAG\n        \"\"\"\n        assert pd_amat.shape[0] == pd_amat.shape[1]\n        nodes = list(pd_amat.columns)\n\n        all_connections = []\n        start, end = np.where(pd_amat != 0)\n        for idx, _ in enumerate(start):\n            all_connections.append((pd_amat.columns[start[idx]], pd_amat.columns[end[idx]]))\n\n        temp = [set(i) for i in all_connections]\n        temp2 = [arc for arc in all_connections if temp.count(set(arc)) &gt; 1]\n        undir_edges = [tuple(item) for item in set(frozenset(item) for item in temp2)]\n\n        dir_edges = [edge for edge in all_connections if edge not in temp2]\n\n        return PDAG(nodes=nodes, dir_edges=dir_edges, undir_edges=undir_edges)\n\n    def remove_edge(self, i: str, j: str) -&gt; None:\n        \"\"\"Removes edge in question.\n\n        Args:\n            i (str): tail\n            j (str): head\n\n        Raises:\n            AssertionError: if edge does not exist\n        \"\"\"\n        if (i, j) not in self.dir_edges and (i, j) not in self.undir_edges:\n            raise AssertionError(\"Edge does not exist in current PDAG\")\n\n        self._undir_edges.discard((i, j))\n        self._dir_edges.discard((i, j))\n        self._children[i].discard(j)\n        self._parents[j].discard(i)\n        self._neighbors[i].discard(j)\n        self._neighbors[j].discard(i)\n        self._undirected_neighbors[i].discard(j)\n        self._undirected_neighbors[j].discard(i)\n\n    def undir_to_dir_edge(self, tail: str, head: str) -&gt; None:\n        \"\"\"Takes a undirected edge and turns it into a directed one.\n\n        tail indicates the starting node of the edge and head the end node, i.e.\n        tail -&gt; head.\n\n        Args:\n            tail (str): starting node\n            head (str): end node\n\n        Raises:\n            AssertionError: if edge does not exist or is not undirected.\n        \"\"\"\n        if (tail, head) not in self.undir_edges and (\n            head,\n            tail,\n        ) not in self.undir_edges:\n            raise AssertionError(\"Edge seems not to be undirected or even there at all.\")\n        self._undir_edges.discard((tail, head))\n        self._undir_edges.discard((head, tail))\n        self._neighbors[tail].discard(head)\n        self._neighbors[head].discard(tail)\n        self._undirected_neighbors[tail].discard(head)\n        self._undirected_neighbors[head].discard(tail)\n\n        self._add_dir_edge(i=tail, j=head)\n\n    def remove_node(self, node: str) -&gt; None:\n        \"\"\"Remove a node from the graph.\n\n        Args:\n            node (str): node to remove\n        \"\"\"\n        self._nodes.remove(node)\n\n        self._dir_edges = {(i, j) for i, j in self._dir_edges if node not in {i, j}}\n\n        self._undir_edges = {(i, j) for i, j in self._undir_edges if node not in {i, j}}\n\n        for child in self._children[node]:\n            self._parents[child].remove(node)\n            self._neighbors[child].remove(node)\n\n        for parent in self._parents[node]:\n            self._children[parent].remove(node)\n            self._neighbors[parent].remove(node)\n\n        for u_nbr in self._undirected_neighbors[node]:\n            self._undirected_neighbors[u_nbr].remove(node)\n            self._neighbors[u_nbr].remove(node)\n\n        self._parents.pop(node, \"I was never here\")\n        self._children.pop(node, \"I was never here\")\n        self._neighbors.pop(node, \"I was never here\")\n        self._undirected_neighbors.pop(node, \"I was never here\")\n\n    def to_dag(self) -&gt; nx.DiGraph:\n        r\"\"\"Algorithm as described in Chickering (2002).\n\n            1. From PDAG P create DAG G containing all directed edges from P\n            2. Repeat the following: Select node v in P s.t.\n                i. v has no outgoing edges (children) i.e. \\\\(ch(v) = \\\\emptyset \\\\)\n\n                ii. \\\\(neigh(v) \\\\neq \\\\emptyset\\\\)\n                    Then \\\\( (pa(v) \\\\cup (neigh(v) \\\\) form a clique.\n                    For each v that is in a clique and is part of an undirected edge in P\n                    i.e. w - v, insert a directed edge w -&gt; v in G.\n                    Remove v and all incident edges from P and continue with next node.\n                    Until all nodes have been deleted from P.\n\n        Returns:\n            nx.DiGraph: DAG that belongs to the MEC implied by the PDAG\n        \"\"\"\n        pdag = self.copy()\n\n        dag = nx.DiGraph()\n        dag.add_nodes_from(pdag.nodes)\n        dag.add_edges_from(pdag.dir_edges)\n\n        if pdag.num_undir_edges == 0:\n            return dag\n        else:\n            while pdag.num_nodes &gt; 0:\n                # find node with (1) no directed outgoing edges and\n                #                (2) the set of undirected neighbors is either empty or\n                #                    undirected neighbors + parents of X are a clique\n                found = False\n                for node in pdag.nodes:\n                    children = pdag.children(node)\n                    neighbors = pdag.neighbors(node)\n                    # pdag._undirected_neighbors[node]\n                    parents = pdag.parents(node)\n                    potential_clique_members = neighbors.union(parents)\n\n                    is_clique = pdag.is_clique(potential_clique_members)\n\n                    if not children and (not neighbors or is_clique):\n                        found = True\n                        # add all edges of node as outgoing edges to dag\n                        for edge in pdag.undir_edges:\n                            if node in edge:\n                                incident_node = list(set(edge) - {node})[0]\n                                dag.add_edge(incident_node, node)\n\n                        pdag.remove_node(node)\n                        break\n\n                if not found:\n                    logger.warning(\"PDAG not extendible: Random DAG on skeleton drawn.\")\n\n                    dag = nx.from_pandas_adjacency(self._amat_to_dag(), create_using=nx.DiGraph)\n\n                    break\n\n            return dag\n\n    @property\n    def adjacency_matrix(self) -&gt; pd.DataFrame:\n        \"\"\"Returns adjacency matrix.\n\n        The i,jth entry being one indicates that there is an edge\n        from i to j. A zero indicates that there is no edge.\n\n        Returns:\n            pd.DataFrame: adjacency matrix\n        \"\"\"\n        amat = pd.DataFrame(\n            np.zeros([self.num_nodes, self.num_nodes]),\n            index=self.nodes,\n            columns=self.nodes,\n        )\n        for edge in self.dir_edges:\n            amat.loc[edge] = 1\n        for edge in self.undir_edges:\n            amat.loc[edge] = amat.loc[edge[::-1]] = 1\n        return amat\n\n    @property\n    def causal_order(self) -&gt; None:\n        \"\"\"Causal order is None.\n\n        This is because PDAGs only allow for a partial causal order.\n\n        Returns:\n            None: None\n        \"\"\"\n        return None\n\n    def _amat_to_dag(self) -&gt; pd.DataFrame:\n        \"\"\"Transform the adjacency matrix of an PDAG to the adjacency matrix.\n\n            of SOME DAG in the Markov equivalence class.\n\n        Returns:\n            pd.DataFrame: DAG, a member of the MEC.\n        \"\"\"\n        pdag_amat = self.adjacency_matrix.to_numpy()\n\n        p = pdag_amat.shape[0]\n        # amat to skel\n        skel = pdag_amat + pdag_amat.T\n        skel[np.where(skel &gt; 1)] = 1\n        # permute skel\n        permute_ord = self.random_state.choice(a=p, size=p, replace=False)\n        skel = skel[:, permute_ord][permute_ord]\n\n        # skel to dag\n        for i in range(1, p):\n            for j in range(0, i + 1):\n                if skel[i, j] == 1:\n                    skel[i, j] = 0\n\n        # inverse permutation\n        i_ord = np.sort(permute_ord)\n        skel = skel[:, i_ord][i_ord]\n        return pd.DataFrame(\n            skel,\n            index=self.adjacency_matrix.index,\n            columns=self.adjacency_matrix.columns,\n        )\n\n    def vstructs(self) -&gt; set[tuple[str, str]]:\n        \"\"\"Retrieve v-structures.\n\n        Returns:\n            set: set of all v-structures\n        \"\"\"\n        vstructures = set()\n        for node in self._nodes:\n            for p1, p2 in combinations(self._parents[node], 2):\n                if p1 not in self._parents[p2] and p2 not in self._parents[p1]:\n                    vstructures.add((p1, node))\n                    vstructures.add((p2, node))\n        return vstructures\n\n    def copy(self) -&gt; PDAG:\n        \"\"\"Return a copy of the graph.\"\"\"\n        return PDAG(\n            nodes=list(self._nodes),\n            dir_edges=list(self._dir_edges),\n            undir_edges=list(self._undir_edges),\n        )\n\n    def show(self) -&gt; None:\n        \"\"\"Plot PDAG.\"\"\"\n        graph = self.to_networkx()\n        pos = nx.circular_layout(graph)\n        nx.draw(graph, pos=pos, with_labels=True)\n\n    def to_networkx(self) -&gt; nx.MultiDiGraph:\n        \"\"\"Convert to networkx graph.\n\n        Returns:\n            nx.MultiDiGraph: Graph with directed and undirected edges.\n        \"\"\"\n        nx_pdag = nx.MultiDiGraph()\n        nx_pdag.add_nodes_from(self.nodes)\n        nx_pdag.add_edges_from(self.dir_edges)\n        for edge in self.undir_edges:\n            nx_pdag.add_edge(*edge)\n            nx_pdag.add_edge(*edge[::-1])\n\n        return nx_pdag\n\n    def _meek_mec_enumeration(self, pdag: PDAG, dag_list: list[DAG]) -&gt; None:\n        \"\"\"Apply Meek's MEC enumeration algorithm.\n\n        Args:\n            pdag (PDAG): partially directed graph in question.\n            dag_list (list): list of currently found DAGs.\n\n        References:\n            Wien\u00f6bst, Marcel, et al. \"Efficient enumeration of Markov equivalent DAGs.\"\n            Proceedings of the AAAI Conference on Artificial Intelligence.\n            Vol. 37. No. 10. 2023.\n        \"\"\"\n        g_copy = pdag.copy()\n        g_copy = self._apply_meek_rules(g_copy)  # Apply Meek rules\n\n        undir_edges = g_copy.undir_edges\n        if undir_edges:\n            i, j = undir_edges[0]  # Take first undirected edge\n\n        if not g_copy.undir_edges:\n            # makes sure that floating nodes are preserved\n            new_member = DAG()\n            new_member.add_nodes_from(g_copy.nodes)\n            new_member.add_edges_from(g_copy.dir_edges)\n            dag_list.append(new_member)\n            return  # Add DAG to current list\n\n        # Recursion first orientation:\n        if not g_copy.undir_edges:\n            return  # Exit if there are no undirected edges\n        i, j = g_copy.undir_edges[0]  # Ensure i and j are defined\n        g_copy.undir_to_dir_edge(i, j)\n        self._meek_mec_enumeration(pdag=g_copy, dag_list=dag_list)\n        g_copy.remove_edge(i, j)\n\n        # Recursion second orientation\n        g_copy._add_dir_edge(j, i)\n        self._meek_mec_enumeration(pdag=g_copy, dag_list=dag_list)\n\n    def to_alldags(self) -&gt; list[DAG]:\n        \"\"\"Recursion algorithm which recursively applies the following steps.\n\n            1. Orient the first undirected edge found.\n            2. Apply Meek rules.\n            3. Recurse with each direction of the oriented edge.\n        This corresponds to Algorithm 2 in Wien\u00f6bst et al. (2023).\n\n        References:\n            Wien\u00f6bst, Marcel, et al. \"Efficient enumeration of Markov equivalent DAGs.\"\n            Proceedings of the AAAI Conference on Artificial Intelligence.\n            Vol. 37. No. 10. 2023.\n        \"\"\"\n        all_dags: list[DAG] = []\n        self._meek_mec_enumeration(pdag=self, dag_list=all_dags)\n        return all_dags\n\n    # use Meek's cpdag2alldag\n    def _apply_meek_rules(self, graph: PDAG) -&gt; PDAG:\n        \"\"\"Apply all four Meek rules to a PDAG turning it into a CPDAG.\n\n        Args:\n            graph (PDAG): PDAG to complete\n        Returns:\n            PDAG: completed PDAG.\n        \"\"\"\n        # Apply Meek Rules\n        cpdag = graph.copy()\n        cpdag = rule_1(pdag=cpdag)\n        cpdag = rule_2(pdag=cpdag)\n        cpdag = rule_3(pdag=cpdag)\n        cpdag = rule_4(pdag=cpdag)\n        return cpdag\n\n    def to_random_dag(self) -&gt; DAG:\n        \"\"\"Provides a random DAG residing in the MEC.\n\n        Returns:\n            nx.DiGraph: random DAG living in MEC\n        \"\"\"\n        to_dag_candidate = self.copy()\n\n        while to_dag_candidate.num_undir_edges &gt; 0:\n            chosen_edge = to_dag_candidate.undir_edges[self.random_state.choice(to_dag_candidate.num_undir_edges)]\n            choose_orientation = [chosen_edge, chosen_edge[::-1]]\n            node_i, node_j = choose_orientation[self.random_state.choice(len(choose_orientation))]\n\n            to_dag_candidate.undir_to_dir_edge(tail=node_i, head=node_j)\n            to_dag_candidate = to_dag_candidate._apply_meek_rules(graph=to_dag_candidate)\n\n        return DAG.from_pandas_adjacency(to_dag_candidate.adjacency_matrix)\n\n    @property\n    def nodes(self) -&gt; list[str]:\n        \"\"\"Get all nods in current PDAG.\n\n        Returns:\n            list: list of nodes.\n        \"\"\"\n        return sorted(list(self._nodes))\n\n    @property\n    def num_nodes(self) -&gt; int:\n        \"\"\"Number of nodes in current PDAG.\n\n        Returns:\n            int: Number of nodes\n        \"\"\"\n        return len(self._nodes)\n\n    @property\n    def num_undir_edges(self) -&gt; int:\n        \"\"\"Number of undirected edges in current PDAG.\n\n        Returns:\n            int: Number of undirected edges\n        \"\"\"\n        return len(self._undir_edges)\n\n    @property\n    def num_dir_edges(self) -&gt; int:\n        \"\"\"Number of directed edges in current PDAG.\n\n        Returns:\n            int: Number of directed edges\n        \"\"\"\n        return len(self._dir_edges)\n\n    @property\n    def num_adjacencies(self) -&gt; int:\n        \"\"\"Number of adjacent nodes in current PDAG.\n\n        Returns:\n            int: Number of adjacent nodes\n        \"\"\"\n        return self.num_undir_edges + self.num_dir_edges\n\n    @property\n    def undir_edges(self) -&gt; list[tuple[str, str]]:\n        \"\"\"Gives all undirected edges in current PDAG.\n\n        Returns:\n            list[tuple[str,str]]: List of undirected edges.\n        \"\"\"\n        return list(self._undir_edges)\n\n    @property\n    def dir_edges(self) -&gt; list[tuple[str, str]]:\n        \"\"\"Gives all directed edges in current PDAG.\n\n        Returns:\n            list[tuple[str,str]]: List of directed edges.\n        \"\"\"\n        return list(self._dir_edges)\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.adjacency_matrix","title":"<code>adjacency_matrix</code>  <code>property</code>","text":"<p>Returns adjacency matrix.</p> <p>The i,jth entry being one indicates that there is an undirected edge between i and j. A zero indicates that there is no edge. The matrix is symmetric.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: adjacency matrix</p>"},{"location":"reference/#hume.graphs.UGRAPH.causal_order","title":"<code>causal_order</code>  <code>property</code>","text":"<p>Causal order is None.</p> <p>This is because undirected graphs do not imply a causal order.</p> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>None</p>"},{"location":"reference/#hume.graphs.UGRAPH.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Gives all edges in current UGRAPH.</p> <p>Returns:</p> Type Description <code>list[tuple[str, str]]</code> <p>list[tuple[str,str]]: List of edges.</p>"},{"location":"reference/#hume.graphs.UGRAPH.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Get all nodes in current UGRAPH.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list[str]</code> <p>list of nodes.</p>"},{"location":"reference/#hume.graphs.UGRAPH.num_edges","title":"<code>num_edges</code>  <code>property</code>","text":"<p>Number of edges in current UGRAPH.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of edges</p>"},{"location":"reference/#hume.graphs.UGRAPH.num_nodes","title":"<code>num_nodes</code>  <code>property</code>","text":"<p>Number of nodes in current UGRAPH.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of nodes</p>"},{"location":"reference/#hume.graphs.UGRAPH.__init__","title":"<code>__init__(nodes=None, edges=None)</code>","text":"<p>UGRAPH constructor.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[str] | None</code> <p>Nodes. Defaults to None.</p> <code>None</code> <code>edges</code> <code>list[tuple[str, str]] | None</code> <p>Edges. Defaults to None.</p> <code>None</code> Source code in <code>hume/graphs.py</code> <pre><code>def __init__(\n    self,\n    nodes: list[str] | None = None,\n    edges: list[tuple[str, str]] | None = None,\n) -&gt; None:\n    \"\"\"UGRAPH constructor.\n\n    Args:\n        nodes (list[str] | None, optional): Nodes. Defaults to None.\n        edges (list[tuple[str,str]] | None, optional): Edges. Defaults to None.\n    \"\"\"\n    if nodes is None:\n        nodes = []\n    if edges is None:\n        edges = []\n\n    self._nodes: set[str] = set(nodes)\n    self._edges: set[tuple[str, str]] = set()\n    self._neighbors: defaultdict[str, set[str]] = defaultdict(set)\n\n    for edge in edges:\n        self._add_edge(*edge)\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.copy","title":"<code>copy()</code>","text":"<p>Return a copy of the graph.</p> Source code in <code>hume/graphs.py</code> <pre><code>def copy(self) -&gt; UGRAPH:\n    \"\"\"Return a copy of the graph.\"\"\"\n    return UGRAPH(nodes=list(self._nodes), edges=list(self._edges))\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.from_pandas_adjacency","title":"<code>from_pandas_adjacency(pd_amat)</code>  <code>classmethod</code>","text":"<p>Build UGRAPH from a Pandas adjacency matrix.</p> <p>Parameters:</p> Name Type Description Default <code>pd_amat</code> <code>DataFrame</code> <p>input adjacency matrix.</p> required <p>Returns:</p> Type Description <code>UGRAPH</code> <p>UGRAPH</p> Source code in <code>hume/graphs.py</code> <pre><code>@classmethod\ndef from_pandas_adjacency(cls, pd_amat: pd.DataFrame) -&gt; UGRAPH:\n    \"\"\"Build UGRAPH from a Pandas adjacency matrix.\n\n    Args:\n        pd_amat (pd.DataFrame): input adjacency matrix.\n\n    Returns:\n        UGRAPH\n    \"\"\"\n    assert pd_amat.shape[0] == pd_amat.shape[1]\n    nodes = list(pd_amat.columns)\n\n    all_connections = []\n    start, end = np.where(pd_amat != 0)\n    for idx, _ in enumerate(start):\n        all_connections.append((pd_amat.columns[start[idx]], pd_amat.columns[end[idx]]))\n\n    edges = [tuple(item) for item in set(frozenset(item) for item in all_connections)]\n\n    return UGRAPH(nodes=nodes, edges=edges)\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.is_adjacent","title":"<code>is_adjacent(i, j)</code>","text":"<p>Return True if the graph contains an undirected edge between i and j.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>str</code> <p>node i.</p> required <code>j</code> <code>str</code> <p>node j.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if i - j</p> Source code in <code>hume/graphs.py</code> <pre><code>def is_adjacent(self, i: str, j: str) -&gt; bool:\n    \"\"\"Return True if the graph contains an undirected edge between i and j.\n\n    Args:\n        i (str): node i.\n        j (str): node j.\n\n    Returns:\n        bool: True if i - j\n    \"\"\"\n    return (i, j) in self._edges or (j, i) in self._edges\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.is_clique","title":"<code>is_clique(potential_clique)</code>","text":"<p>Check every pair of nodes in potential_clique is adjacent.</p> Source code in <code>hume/graphs.py</code> <pre><code>def is_clique(self, potential_clique: set[str]) -&gt; bool:\n    \"\"\"Check every pair of nodes in potential_clique is adjacent.\"\"\"\n    return all(self.is_adjacent(i, j) for i, j in combinations(potential_clique, 2))\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.neighbors","title":"<code>neighbors(node)</code>","text":"<p>Gives all neighbors of node <code>node</code>.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>node in current UGRAPH.</p> required <p>Returns:</p> Name Type Description <code>set</code> <code>set[str]</code> <p>set of neighbors.</p> Source code in <code>hume/graphs.py</code> <pre><code>def neighbors(self, node: str) -&gt; set[str]:\n    \"\"\"Gives all neighbors of node `node`.\n\n    Args:\n        node (str): node in current UGRAPH.\n\n    Returns:\n        set: set of neighbors.\n    \"\"\"\n    if node in self._neighbors:\n        return self._neighbors[node]\n    else:\n        return set()\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.remove_edge","title":"<code>remove_edge(i, j)</code>","text":"<p>Removes edge in question.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>str</code> <p>first node</p> required <code>j</code> <code>str</code> <p>second node</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>if edge does not exist</p> Source code in <code>hume/graphs.py</code> <pre><code>def remove_edge(self, i: str, j: str) -&gt; None:\n    \"\"\"Removes edge in question.\n\n    Args:\n        i (str): first node\n        j (str): second node\n\n    Raises:\n        AssertionError: if edge does not exist\n    \"\"\"\n    if not self.is_adjacent(i, j):\n        raise AssertionError(\"Edge does not exist in current UGRAPH\")\n\n    self._edges.discard((i, j))\n    self._edges.discard((j, i))\n    self._neighbors[i].discard(j)\n    self._neighbors[j].discard(i)\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.remove_node","title":"<code>remove_node(node)</code>","text":"<p>Remove a node from the graph.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>node to remove</p> required Source code in <code>hume/graphs.py</code> <pre><code>def remove_node(self, node: str) -&gt; None:\n    \"\"\"Remove a node from the graph.\n\n    Args:\n        node (str): node to remove\n    \"\"\"\n    self._nodes.remove(node)\n\n    self._edges = {(i, j) for i, j in self._edges if node not in {i, j}}\n\n    for nbr in self._neighbors[node]:\n        self._neighbors[nbr].discard(node)\n\n    self._neighbors.pop(node, \"I was never here\")\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.show","title":"<code>show()</code>","text":"<p>Plot UGRAPH.</p> Source code in <code>hume/graphs.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Plot UGRAPH.\"\"\"\n    graph = self.to_networkx()\n    pos = nx.circular_layout(graph)\n    nx.draw(graph, pos=pos, with_labels=True)\n</code></pre>"},{"location":"reference/#hume.graphs.UGRAPH.to_networkx","title":"<code>to_networkx()</code>","text":"<p>Convert to networkx graph.</p> <p>Returns:</p> Type Description <code>Graph</code> <p>nx.Graph: Undirected networkx graph.</p> Source code in <code>hume/graphs.py</code> <pre><code>def to_networkx(self) -&gt; nx.Graph:\n    \"\"\"Convert to networkx graph.\n\n    Returns:\n        nx.Graph: Undirected networkx graph.\n    \"\"\"\n    nx_ugraph = nx.Graph()\n    nx_ugraph.add_nodes_from(self.nodes)\n    nx_ugraph.add_edges_from(self.edges)\n    return nx_ugraph\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.adjacency_matrix","title":"<code>adjacency_matrix</code>  <code>property</code>","text":"<p>Returns adjacency matrix.</p> <p>The i,jth entry being one indicates that there is an edge from i to j. A zero indicates that there is no edge.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: adjacency matrix</p>"},{"location":"reference/#hume.graphs.PDAG.causal_order","title":"<code>causal_order</code>  <code>property</code>","text":"<p>Causal order is None.</p> <p>This is because PDAGs only allow for a partial causal order.</p> <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>None</p>"},{"location":"reference/#hume.graphs.PDAG.dir_edges","title":"<code>dir_edges</code>  <code>property</code>","text":"<p>Gives all directed edges in current PDAG.</p> <p>Returns:</p> Type Description <code>list[tuple[str, str]]</code> <p>list[tuple[str,str]]: List of directed edges.</p>"},{"location":"reference/#hume.graphs.PDAG.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Get all nods in current PDAG.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list[str]</code> <p>list of nodes.</p>"},{"location":"reference/#hume.graphs.PDAG.num_adjacencies","title":"<code>num_adjacencies</code>  <code>property</code>","text":"<p>Number of adjacent nodes in current PDAG.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of adjacent nodes</p>"},{"location":"reference/#hume.graphs.PDAG.num_dir_edges","title":"<code>num_dir_edges</code>  <code>property</code>","text":"<p>Number of directed edges in current PDAG.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of directed edges</p>"},{"location":"reference/#hume.graphs.PDAG.num_nodes","title":"<code>num_nodes</code>  <code>property</code>","text":"<p>Number of nodes in current PDAG.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of nodes</p>"},{"location":"reference/#hume.graphs.PDAG.num_undir_edges","title":"<code>num_undir_edges</code>  <code>property</code>","text":"<p>Number of undirected edges in current PDAG.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of undirected edges</p>"},{"location":"reference/#hume.graphs.PDAG.undir_edges","title":"<code>undir_edges</code>  <code>property</code>","text":"<p>Gives all undirected edges in current PDAG.</p> <p>Returns:</p> Type Description <code>list[tuple[str, str]]</code> <p>list[tuple[str,str]]: List of undirected edges.</p>"},{"location":"reference/#hume.graphs.PDAG.__init__","title":"<code>__init__(nodes=None, dir_edges=None, undir_edges=None)</code>","text":"<p>PDAG constructor.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[str] | None</code> <p>Nodes in the PDAG. Defaults to None.</p> <code>None</code> <code>dir_edges</code> <code>list[tuple[str, str]] | None</code> <p>directed edges. Defaults to None.</p> <code>None</code> <code>undir_edges</code> <code>list[tuple[str, str]] | None</code> <p>undirected edges. Defaults to None.</p> <code>None</code> Source code in <code>hume/graphs.py</code> <pre><code>def __init__(\n    self,\n    nodes: list[str] | None = None,\n    dir_edges: list[tuple[str, str]] | None = None,\n    undir_edges: list[tuple[str, str]] | None = None,\n) -&gt; None:\n    \"\"\"PDAG constructor.\n\n    Args:\n        nodes (list[str] | None, optional): Nodes in the PDAG. Defaults to None.\n        dir_edges (list[tuple[str,str]] | None, optional): directed edges. Defaults to None.\n        undir_edges (list[tuple[str,str]] | None, optional): undirected edges. Defaults to None.\n    \"\"\"\n    if nodes is None:\n        nodes = []\n    if dir_edges is None:\n        dir_edges = []\n    if undir_edges is None:\n        undir_edges = []\n\n    self._nodes = set(nodes)\n    self._undir_edges: set[tuple[str, str]] = set()\n    self._dir_edges: set[tuple[str, str]] = set()\n    self._parents: defaultdict[str, set[str]] = defaultdict(set)\n    self._children: defaultdict[str, set[str]] = defaultdict(set)\n    self._neighbors: defaultdict[str, set[str]] = defaultdict(set)\n    self._undirected_neighbors: defaultdict[str, set[str]] = defaultdict(set)\n    self.random_state: np.random.Generator = np.random.default_rng(seed=2026)\n\n    for dir_edge in dir_edges:\n        self._add_dir_edge(*dir_edge)\n    for unir_edge in undir_edges:\n        self._add_undir_edge(*unir_edge)\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.children","title":"<code>children(node)</code>","text":"<p>Gives all children of node <code>node</code>.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>node in current PDAG.</p> required <p>Returns:</p> Name Type Description <code>set</code> <code>set[str]</code> <p>set of children.</p> Source code in <code>hume/graphs.py</code> <pre><code>def children(self, node: str) -&gt; set[str]:\n    \"\"\"Gives all children of node `node`.\n\n    Args:\n        node (str): node in current PDAG.\n\n    Returns:\n        set: set of children.\n    \"\"\"\n    if node in self._children:\n        return self._children[node]\n    else:\n        return set()\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.copy","title":"<code>copy()</code>","text":"<p>Return a copy of the graph.</p> Source code in <code>hume/graphs.py</code> <pre><code>def copy(self) -&gt; PDAG:\n    \"\"\"Return a copy of the graph.\"\"\"\n    return PDAG(\n        nodes=list(self._nodes),\n        dir_edges=list(self._dir_edges),\n        undir_edges=list(self._undir_edges),\n    )\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.from_pandas_adjacency","title":"<code>from_pandas_adjacency(pd_amat)</code>  <code>classmethod</code>","text":"<p>Build PDAG from a Pandas adjacency matrix.</p> <p>Parameters:</p> Name Type Description Default <code>pd_amat</code> <code>DataFrame</code> <p>input adjacency matrix.</p> required <p>Returns:</p> Type Description <code>PDAG</code> <p>PDAG</p> Source code in <code>hume/graphs.py</code> <pre><code>@classmethod\ndef from_pandas_adjacency(cls, pd_amat: pd.DataFrame) -&gt; PDAG:\n    \"\"\"Build PDAG from a Pandas adjacency matrix.\n\n    Args:\n        pd_amat (pd.DataFrame): input adjacency matrix.\n\n    Returns:\n        PDAG\n    \"\"\"\n    assert pd_amat.shape[0] == pd_amat.shape[1]\n    nodes = list(pd_amat.columns)\n\n    all_connections = []\n    start, end = np.where(pd_amat != 0)\n    for idx, _ in enumerate(start):\n        all_connections.append((pd_amat.columns[start[idx]], pd_amat.columns[end[idx]]))\n\n    temp = [set(i) for i in all_connections]\n    temp2 = [arc for arc in all_connections if temp.count(set(arc)) &gt; 1]\n    undir_edges = [tuple(item) for item in set(frozenset(item) for item in temp2)]\n\n    dir_edges = [edge for edge in all_connections if edge not in temp2]\n\n    return PDAG(nodes=nodes, dir_edges=dir_edges, undir_edges=undir_edges)\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.is_adjacent","title":"<code>is_adjacent(i, j)</code>","text":"<p>Return True if the graph contains an directed or undirected edge between i and j.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>str</code> <p>node i.</p> required <code>j</code> <code>str</code> <p>node j.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if i-j or i-&gt;j or i&lt;-j</p> Source code in <code>hume/graphs.py</code> <pre><code>def is_adjacent(self, i: str, j: str) -&gt; bool:\n    \"\"\"Return True if the graph contains an directed or undirected edge between i and j.\n\n    Args:\n        i (str): node i.\n        j (str): node j.\n\n    Returns:\n        bool: True if i-j or i-&gt;j or i&lt;-j\n    \"\"\"\n    return any((\n        (j, i) in self.dir_edges or (j, i) in self.undir_edges,\n        (i, j) in self.dir_edges or (i, j) in self.undir_edges,\n    ))\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.is_clique","title":"<code>is_clique(potential_clique)</code>","text":"<p>Check every pair of node X potential_clique is adjacent.</p> Source code in <code>hume/graphs.py</code> <pre><code>def is_clique(self, potential_clique: set[str]) -&gt; bool:\n    \"\"\"Check every pair of node X potential_clique is adjacent.\"\"\"\n    return all(self.is_adjacent(i, j) for i, j in combinations(potential_clique, 2))\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.neighbors","title":"<code>neighbors(node)</code>","text":"<p>Gives all neighbors of node <code>node</code>.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>node in current PDAG.</p> required <p>Returns:</p> Name Type Description <code>set</code> <code>set[str]</code> <p>set of neighbors.</p> Source code in <code>hume/graphs.py</code> <pre><code>def neighbors(self, node: str) -&gt; set[str]:\n    \"\"\"Gives all neighbors of node `node`.\n\n    Args:\n        node (str): node in current PDAG.\n\n    Returns:\n        set: set of neighbors.\n    \"\"\"\n    if node in self._neighbors:\n        return self._neighbors[node]\n    else:\n        return set()\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.parents","title":"<code>parents(node)</code>","text":"<p>Gives all parents of node <code>node</code>.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>node in current PDAG.</p> required <p>Returns:</p> Name Type Description <code>set</code> <code>set[str]</code> <p>set of parents.</p> Source code in <code>hume/graphs.py</code> <pre><code>def parents(self, node: str) -&gt; set[str]:\n    \"\"\"Gives all parents of node `node`.\n\n    Args:\n        node (str): node in current PDAG.\n\n    Returns:\n        set: set of parents.\n    \"\"\"\n    if node in self._parents:\n        return self._parents[node]\n    else:\n        return set()\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.remove_edge","title":"<code>remove_edge(i, j)</code>","text":"<p>Removes edge in question.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>str</code> <p>tail</p> required <code>j</code> <code>str</code> <p>head</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>if edge does not exist</p> Source code in <code>hume/graphs.py</code> <pre><code>def remove_edge(self, i: str, j: str) -&gt; None:\n    \"\"\"Removes edge in question.\n\n    Args:\n        i (str): tail\n        j (str): head\n\n    Raises:\n        AssertionError: if edge does not exist\n    \"\"\"\n    if (i, j) not in self.dir_edges and (i, j) not in self.undir_edges:\n        raise AssertionError(\"Edge does not exist in current PDAG\")\n\n    self._undir_edges.discard((i, j))\n    self._dir_edges.discard((i, j))\n    self._children[i].discard(j)\n    self._parents[j].discard(i)\n    self._neighbors[i].discard(j)\n    self._neighbors[j].discard(i)\n    self._undirected_neighbors[i].discard(j)\n    self._undirected_neighbors[j].discard(i)\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.remove_node","title":"<code>remove_node(node)</code>","text":"<p>Remove a node from the graph.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>node to remove</p> required Source code in <code>hume/graphs.py</code> <pre><code>def remove_node(self, node: str) -&gt; None:\n    \"\"\"Remove a node from the graph.\n\n    Args:\n        node (str): node to remove\n    \"\"\"\n    self._nodes.remove(node)\n\n    self._dir_edges = {(i, j) for i, j in self._dir_edges if node not in {i, j}}\n\n    self._undir_edges = {(i, j) for i, j in self._undir_edges if node not in {i, j}}\n\n    for child in self._children[node]:\n        self._parents[child].remove(node)\n        self._neighbors[child].remove(node)\n\n    for parent in self._parents[node]:\n        self._children[parent].remove(node)\n        self._neighbors[parent].remove(node)\n\n    for u_nbr in self._undirected_neighbors[node]:\n        self._undirected_neighbors[u_nbr].remove(node)\n        self._neighbors[u_nbr].remove(node)\n\n    self._parents.pop(node, \"I was never here\")\n    self._children.pop(node, \"I was never here\")\n    self._neighbors.pop(node, \"I was never here\")\n    self._undirected_neighbors.pop(node, \"I was never here\")\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.show","title":"<code>show()</code>","text":"<p>Plot PDAG.</p> Source code in <code>hume/graphs.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Plot PDAG.\"\"\"\n    graph = self.to_networkx()\n    pos = nx.circular_layout(graph)\n    nx.draw(graph, pos=pos, with_labels=True)\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.to_alldags","title":"<code>to_alldags()</code>","text":"<p>Recursion algorithm which recursively applies the following steps.</p> <pre><code>1. Orient the first undirected edge found.\n2. Apply Meek rules.\n3. Recurse with each direction of the oriented edge.\n</code></pre> <p>This corresponds to Algorithm 2 in Wien\u00f6bst et al. (2023).</p> References <p>Wien\u00f6bst, Marcel, et al. \"Efficient enumeration of Markov equivalent DAGs.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 10. 2023.</p> Source code in <code>hume/graphs.py</code> <pre><code>def to_alldags(self) -&gt; list[DAG]:\n    \"\"\"Recursion algorithm which recursively applies the following steps.\n\n        1. Orient the first undirected edge found.\n        2. Apply Meek rules.\n        3. Recurse with each direction of the oriented edge.\n    This corresponds to Algorithm 2 in Wien\u00f6bst et al. (2023).\n\n    References:\n        Wien\u00f6bst, Marcel, et al. \"Efficient enumeration of Markov equivalent DAGs.\"\n        Proceedings of the AAAI Conference on Artificial Intelligence.\n        Vol. 37. No. 10. 2023.\n    \"\"\"\n    all_dags: list[DAG] = []\n    self._meek_mec_enumeration(pdag=self, dag_list=all_dags)\n    return all_dags\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.to_dag","title":"<code>to_dag()</code>","text":"<p>Algorithm as described in Chickering (2002).</p> <pre><code>1. From PDAG P create DAG G containing all directed edges from P\n2. Repeat the following: Select node v in P s.t.\n    i. v has no outgoing edges (children) i.e. \\\\(ch(v) = \\\\emptyset \\\\)\n\n    ii. \\\\(neigh(v) \\\\neq \\\\emptyset\\\\)\n        Then \\\\( (pa(v) \\\\cup (neigh(v) \\\\) form a clique.\n        For each v that is in a clique and is part of an undirected edge in P\n        i.e. w - v, insert a directed edge w -&gt; v in G.\n        Remove v and all incident edges from P and continue with next node.\n        Until all nodes have been deleted from P.\n</code></pre> <p>Returns:</p> Type Description <code>DiGraph</code> <p>nx.DiGraph: DAG that belongs to the MEC implied by the PDAG</p> Source code in <code>hume/graphs.py</code> <pre><code>def to_dag(self) -&gt; nx.DiGraph:\n    r\"\"\"Algorithm as described in Chickering (2002).\n\n        1. From PDAG P create DAG G containing all directed edges from P\n        2. Repeat the following: Select node v in P s.t.\n            i. v has no outgoing edges (children) i.e. \\\\(ch(v) = \\\\emptyset \\\\)\n\n            ii. \\\\(neigh(v) \\\\neq \\\\emptyset\\\\)\n                Then \\\\( (pa(v) \\\\cup (neigh(v) \\\\) form a clique.\n                For each v that is in a clique and is part of an undirected edge in P\n                i.e. w - v, insert a directed edge w -&gt; v in G.\n                Remove v and all incident edges from P and continue with next node.\n                Until all nodes have been deleted from P.\n\n    Returns:\n        nx.DiGraph: DAG that belongs to the MEC implied by the PDAG\n    \"\"\"\n    pdag = self.copy()\n\n    dag = nx.DiGraph()\n    dag.add_nodes_from(pdag.nodes)\n    dag.add_edges_from(pdag.dir_edges)\n\n    if pdag.num_undir_edges == 0:\n        return dag\n    else:\n        while pdag.num_nodes &gt; 0:\n            # find node with (1) no directed outgoing edges and\n            #                (2) the set of undirected neighbors is either empty or\n            #                    undirected neighbors + parents of X are a clique\n            found = False\n            for node in pdag.nodes:\n                children = pdag.children(node)\n                neighbors = pdag.neighbors(node)\n                # pdag._undirected_neighbors[node]\n                parents = pdag.parents(node)\n                potential_clique_members = neighbors.union(parents)\n\n                is_clique = pdag.is_clique(potential_clique_members)\n\n                if not children and (not neighbors or is_clique):\n                    found = True\n                    # add all edges of node as outgoing edges to dag\n                    for edge in pdag.undir_edges:\n                        if node in edge:\n                            incident_node = list(set(edge) - {node})[0]\n                            dag.add_edge(incident_node, node)\n\n                    pdag.remove_node(node)\n                    break\n\n            if not found:\n                logger.warning(\"PDAG not extendible: Random DAG on skeleton drawn.\")\n\n                dag = nx.from_pandas_adjacency(self._amat_to_dag(), create_using=nx.DiGraph)\n\n                break\n\n        return dag\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.to_networkx","title":"<code>to_networkx()</code>","text":"<p>Convert to networkx graph.</p> <p>Returns:</p> Type Description <code>MultiDiGraph</code> <p>nx.MultiDiGraph: Graph with directed and undirected edges.</p> Source code in <code>hume/graphs.py</code> <pre><code>def to_networkx(self) -&gt; nx.MultiDiGraph:\n    \"\"\"Convert to networkx graph.\n\n    Returns:\n        nx.MultiDiGraph: Graph with directed and undirected edges.\n    \"\"\"\n    nx_pdag = nx.MultiDiGraph()\n    nx_pdag.add_nodes_from(self.nodes)\n    nx_pdag.add_edges_from(self.dir_edges)\n    for edge in self.undir_edges:\n        nx_pdag.add_edge(*edge)\n        nx_pdag.add_edge(*edge[::-1])\n\n    return nx_pdag\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.to_random_dag","title":"<code>to_random_dag()</code>","text":"<p>Provides a random DAG residing in the MEC.</p> <p>Returns:</p> Type Description <code>DAG</code> <p>nx.DiGraph: random DAG living in MEC</p> Source code in <code>hume/graphs.py</code> <pre><code>def to_random_dag(self) -&gt; DAG:\n    \"\"\"Provides a random DAG residing in the MEC.\n\n    Returns:\n        nx.DiGraph: random DAG living in MEC\n    \"\"\"\n    to_dag_candidate = self.copy()\n\n    while to_dag_candidate.num_undir_edges &gt; 0:\n        chosen_edge = to_dag_candidate.undir_edges[self.random_state.choice(to_dag_candidate.num_undir_edges)]\n        choose_orientation = [chosen_edge, chosen_edge[::-1]]\n        node_i, node_j = choose_orientation[self.random_state.choice(len(choose_orientation))]\n\n        to_dag_candidate.undir_to_dir_edge(tail=node_i, head=node_j)\n        to_dag_candidate = to_dag_candidate._apply_meek_rules(graph=to_dag_candidate)\n\n    return DAG.from_pandas_adjacency(to_dag_candidate.adjacency_matrix)\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.undir_neighbors","title":"<code>undir_neighbors(node)</code>","text":"<p>Gives all undirected neighbors of node <code>node</code>.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>node in current PDAG.</p> required <p>Returns:</p> Name Type Description <code>set</code> <code>set[str]</code> <p>set of undirected neighbors.</p> Source code in <code>hume/graphs.py</code> <pre><code>def undir_neighbors(self, node: str) -&gt; set[str]:\n    \"\"\"Gives all undirected neighbors of node `node`.\n\n    Args:\n        node (str): node in current PDAG.\n\n    Returns:\n        set: set of undirected neighbors.\n    \"\"\"\n    if node in self._undirected_neighbors:\n        return self._undirected_neighbors[node]\n    else:\n        return set()\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.undir_to_dir_edge","title":"<code>undir_to_dir_edge(tail, head)</code>","text":"<p>Takes a undirected edge and turns it into a directed one.</p> <p>tail indicates the starting node of the edge and head the end node, i.e. tail -&gt; head.</p> <p>Parameters:</p> Name Type Description Default <code>tail</code> <code>str</code> <p>starting node</p> required <code>head</code> <code>str</code> <p>end node</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>if edge does not exist or is not undirected.</p> Source code in <code>hume/graphs.py</code> <pre><code>def undir_to_dir_edge(self, tail: str, head: str) -&gt; None:\n    \"\"\"Takes a undirected edge and turns it into a directed one.\n\n    tail indicates the starting node of the edge and head the end node, i.e.\n    tail -&gt; head.\n\n    Args:\n        tail (str): starting node\n        head (str): end node\n\n    Raises:\n        AssertionError: if edge does not exist or is not undirected.\n    \"\"\"\n    if (tail, head) not in self.undir_edges and (\n        head,\n        tail,\n    ) not in self.undir_edges:\n        raise AssertionError(\"Edge seems not to be undirected or even there at all.\")\n    self._undir_edges.discard((tail, head))\n    self._undir_edges.discard((head, tail))\n    self._neighbors[tail].discard(head)\n    self._neighbors[head].discard(tail)\n    self._undirected_neighbors[tail].discard(head)\n    self._undirected_neighbors[head].discard(tail)\n\n    self._add_dir_edge(i=tail, j=head)\n</code></pre>"},{"location":"reference/#hume.graphs.PDAG.vstructs","title":"<code>vstructs()</code>","text":"<p>Retrieve v-structures.</p> <p>Returns:</p> Name Type Description <code>set</code> <code>set[tuple[str, str]]</code> <p>set of all v-structures</p> Source code in <code>hume/graphs.py</code> <pre><code>def vstructs(self) -&gt; set[tuple[str, str]]:\n    \"\"\"Retrieve v-structures.\n\n    Returns:\n        set: set of all v-structures\n    \"\"\"\n    vstructures = set()\n    for node in self._nodes:\n        for p1, p2 in combinations(self._parents[node], 2):\n            if p1 not in self._parents[p2] and p2 not in self._parents[p1]:\n                vstructures.add((p1, node))\n                vstructures.add((p2, node))\n    return vstructures\n</code></pre>"},{"location":"reference/#correlation-functions","title":"Correlation Functions","text":"<p>               Bases: <code>CorrelationMeasure</code></p> <p>Maximum-likelihood polychoric correlation between two ordinal variables.</p> <p>Both variables are treated as discretised versions of latent normal variates. The MLE of their latent correlation is found by one of two solvers:</p> <ul> <li> <p><code>\"brent\"</code> (default) \u2014 Direct maximisation of   $\\ell(\\rho) = \\sum_{ij} n_{ij}\\log\\pi_{ij}$ via   :func:<code>scipy.optimize.minimize_scalar</code> with Brent's bounded method.   Each function evaluation requires only :func:<code>_pi_rs</code> (no derivatives).   Converges super-linearly and is consistently faster once the number of   ordinal categories exceeds ~3, because the per-evaluation cost grows as   $O(k_x \\times k_y)$ CDF calls rather than CDF + PDF calls.</p> </li> <li> <p><code>\"newton\"</code> \u2014 Fisher scoring.  Uses the score   $S(\\rho) = \\sum_{ij} n_{ij}\\,(\\pi_{ij}'/\\pi_{ij})$ and the empirical   Fisher information $\\hat{I}(\\rho) = \\sum_{ij} n_{ij}\\,(\\pi_{ij}'/\\pi_{ij})^2$   to iterate $\\rho \\leftarrow \\rho + S/\\hat{I}$ until convergence.   Converges quadratically near the MLE and can be ~2\u00d7 faster than   <code>\"brent\"</code> for binary variables ($k_x = k_y = 2$), but becomes   progressively slower as the category count grows because each iteration   requires both :func:<code>_pi_rs</code> and :func:<code>_pi_rs_derivative</code> per cell.   Consider this solver when both variables are binary or ternary.</p> </li> </ul> <p>Solver selection guide (rule of thumb from benchmarks):</p> <p>+-------------------+------------------+ | Category count    | Recommended      | +===================+==================+ | binary (2 \u00d7 2)    | <code>\"newton\"</code>     | +-------------------+------------------+ | ternary (3 \u00d7 3)   | either           | +-------------------+------------------+ | 4+ categories     | <code>\"brent\"</code>      | +-------------------+------------------+</p> <p>Parameters:</p> Name Type Description Default <code>max_cor</code> <code>float</code> <p>Absolute upper bound for the estimated correlation. Defaults to 0.9999.</p> <code>0.9999</code> <code>solver</code> <code>Literal['newton', 'brent']</code> <p>Optimisation strategy, <code>\"brent\"</code> or <code>\"newton\"</code>. Defaults to <code>\"brent\"</code>.</p> <code>'brent'</code> <code>max_iter</code> <code>int</code> <p>Maximum Fisher-scoring iterations (ignored for <code>\"brent\"</code>). Defaults to 100.</p> <code>100</code> <code>tol</code> <code>float</code> <p>Convergence tolerance on the absolute score value and step size (ignored for <code>\"brent\"</code>). Defaults to 1e-10.</p> <code>1e-10</code> <p>Example::</p> <pre><code>rho = PolychoricCorrelation().fit(x_ord, y_ord).correlation\nrho = PolychoricCorrelation(solver=\"newton\").fit(x_ord, y_ord).correlation\n</code></pre> Source code in <code>hume/correlation.py</code> <pre><code>class PolychoricCorrelation(CorrelationMeasure):\n    r\"\"\"Maximum-likelihood polychoric correlation between two ordinal variables.\n\n    Both variables are treated as discretised versions of latent normal variates.\n    The MLE of their latent correlation is found by one of two solvers:\n\n    * ``\"brent\"`` (**default**) \u2014 Direct maximisation of\n      $\\\\ell(\\\\rho) = \\\\sum_{ij} n_{ij}\\\\log\\\\pi_{ij}$ via\n      :func:`scipy.optimize.minimize_scalar` with Brent's bounded method.\n      Each function evaluation requires only :func:`_pi_rs` (no derivatives).\n      Converges super-linearly and is consistently faster once the number of\n      ordinal categories exceeds ~3, because the per-evaluation cost grows as\n      $O(k_x \\\\times k_y)$ CDF calls rather than CDF + PDF calls.\n\n    * ``\"newton\"`` \u2014 Fisher scoring.  Uses the score\n      $S(\\\\rho) = \\\\sum_{ij} n_{ij}\\\\,(\\\\pi_{ij}'/\\\\pi_{ij})$ and the empirical\n      Fisher information $\\\\hat{I}(\\\\rho) = \\\\sum_{ij} n_{ij}\\\\,(\\\\pi_{ij}'/\\\\pi_{ij})^2$\n      to iterate $\\\\rho \\\\leftarrow \\\\rho + S/\\\\hat{I}$ until convergence.\n      Converges quadratically near the MLE and can be ~2\u00d7 faster than\n      ``\"brent\"`` for binary variables ($k_x = k_y = 2$), but becomes\n      progressively slower as the category count grows because each iteration\n      requires both :func:`_pi_rs` and :func:`_pi_rs_derivative` per cell.\n      Consider this solver when both variables are binary or ternary.\n\n    **Solver selection guide** (rule of thumb from benchmarks):\n\n    +-------------------+------------------+\n    | Category count    | Recommended      |\n    +===================+==================+\n    | binary (2 \u00d7 2)    | ``\"newton\"``     |\n    +-------------------+------------------+\n    | ternary (3 \u00d7 3)   | either           |\n    +-------------------+------------------+\n    | 4+ categories     | ``\"brent\"``      |\n    +-------------------+------------------+\n\n    Args:\n        max_cor: Absolute upper bound for the estimated correlation.\n            Defaults to 0.9999.\n        solver: Optimisation strategy, ``\"brent\"`` or ``\"newton\"``.\n            Defaults to ``\"brent\"``.\n        max_iter: Maximum Fisher-scoring iterations (ignored for ``\"brent\"``).\n            Defaults to 100.\n        tol: Convergence tolerance on the absolute score value and step size\n            (ignored for ``\"brent\"``).\n            Defaults to 1e-10.\n\n    Example::\n\n        rho = PolychoricCorrelation().fit(x_ord, y_ord).correlation\n        rho = PolychoricCorrelation(solver=\"newton\").fit(x_ord, y_ord).correlation\n    \"\"\"\n\n    def __init__(\n        self,\n        max_cor: float = 0.9999,\n        solver: Literal[\"newton\", \"brent\"] = \"brent\",\n        max_iter: int = 100,\n        tol: float = 1e-10,\n    ) -&gt; None:\n        \"\"\"Initialise the polychoric correlation estimator.\n\n        Args:\n            max_cor: Absolute upper bound for the estimated correlation.\n                Defaults to 0.9999.\n            solver: Optimisation strategy.  ``\"brent\"`` (default) is faster\n                for variables with 4 or more ordinal categories.\n                ``\"newton\"`` (Fisher scoring) can be ~2\u00d7 faster for binary\n                variables but slows down as category count grows.\n            max_iter: Maximum Fisher-scoring iterations; ignored when\n                ``solver=\"brent\"``.  Defaults to 100.\n            tol: Convergence tolerance on the absolute score value and step\n                size; ignored when ``solver=\"brent\"``.  Defaults to 1e-10.\n\n        Raises:\n            ValueError: If *solver* is not ``\"newton\"`` or ``\"brent\"``.\n        \"\"\"\n        super().__init__(max_cor=max_cor)\n        if solver not in {\"newton\", \"brent\"}:\n            raise ValueError(f\"`solver` must be 'newton' or 'brent', got '{solver}'.\")\n        self._solver = solver\n        self._max_iter = max_iter\n        self._tol = tol\n\n    def fit(self, x: np.ndarray, y: np.ndarray) -&gt; PolychoricCorrelation:\n        \"\"\"Fit the polychoric correlation model.\n\n        Args:\n            x: First ordinal variable (integer-valued or small number of\n                distinct float levels).\n            y: Second ordinal variable.\n\n        Returns:\n            *self*\n\n        Raises:\n            ValueError: On invalid or incompatible inputs.\n            RuntimeError: If the solver cannot converge.\n        \"\"\"\n        x_arr, y_arr = self._prepare(x, y)\n        _validate_ordinal(x_arr, \"x\")\n        _validate_ordinal(y_arr, \"y\")\n\n        self._correlation = self._clip(self._polychoric(x_arr, y_arr))\n        return self\n\n    # ------------------------------------------------------------------\n    # Dispatch\n    # ------------------------------------------------------------------\n\n    def _polychoric(self, x: np.ndarray, y: np.ndarray) -&gt; float:\n        \"\"\"Build shared data structures, then dispatch to the chosen solver.\"\"\"\n        n = x.size\n        ux = np.unique(x)\n        uy = np.unique(y)\n\n        n_rs = np.array(\n            [[np.sum((x == xi) &amp; (y == yj)) for yj in uy] for xi in ux],\n            dtype=float,\n        )\n        assert n_rs.sum() == n, \"Joint frequency table does not sum to n.\"\n\n        tx = _thresholds(x)\n        ty = _thresholds(y)\n\n        if self._solver == \"newton\":\n            return self._polychoric_newton(n_rs, tx, ty, ux, uy)\n        return self._polychoric_brent(n_rs, tx, ty, ux, uy)\n\n    # ------------------------------------------------------------------\n    # Solver: Fisher scoring (Newton-type)\n    # ------------------------------------------------------------------\n\n    def _polychoric_newton(\n        self,\n        n_rs: np.ndarray,\n        tx: np.ndarray,\n        ty: np.ndarray,\n        ux: np.ndarray,\n        uy: np.ndarray,\n    ) -&gt; float:\n        r\"\"\"Fisher scoring iteration on the score equation.\n\n        Update rule: $\\\\rho \\\\leftarrow \\\\rho + S(\\\\rho)/\\\\hat{I}(\\\\rho)$\n\n        where $S = \\\\sum n_{ij}\\\\,(dp/p)$ is the score and\n        $\\\\hat{I} = \\\\sum n_{ij}\\\\,(dp/p)^2$ is the empirical Fisher information.\n        Both $\\\\pi_{ij}$ and $\\\\pi_{ij}'$ are needed per cell per iteration;\n        the step converges quadratically in the neighbourhood of the MLE.\n        \"\"\"\n        rho = 0.0\n        bound = self._max_cor\n        score_val = 0.0\n\n        for iteration in range(self._max_iter):\n            score_val = 0.0\n            info_val = 0.0\n\n            for i in range(len(ux)):\n                for j in range(len(uy)):\n                    lower = (float(tx[i]), float(ty[j]))\n                    upper = (float(tx[i + 1]), float(ty[j + 1]))\n                    p = max(_pi_rs(lower=lower, upper=upper, corr=rho), _CELL_FLOOR)\n                    dp = _pi_rs_derivative(lower=np.array(lower), upper=np.array(upper), corr=rho)\n                    ratio = dp / p\n                    score_val += n_rs[i, j] * ratio\n                    info_val += n_rs[i, j] * ratio**2\n\n            if abs(score_val) &lt; self._tol:\n                break\n            if info_val &lt; 1e-14:  # nearly flat \u2014 cannot determine direction\n                logger.warning(\n                    \"Fisher information \u2248 0 at \u03c1=%.4f after %d iteration(s); returning current estimate.\",\n                    rho,\n                    iteration,\n                )\n                break\n\n            step = score_val / info_val\n            rho_new = float(np.clip(rho + step, -bound, bound))\n\n            if abs(rho_new - rho) &lt; self._tol:\n                rho = rho_new\n                break\n            rho = rho_new\n        else:\n            logger.warning(\n                \"Fisher scoring did not converge in %d iterations (|score|=%.2e). \"\n                \"Consider increasing max_iter or switching to solver='brent'.\",\n                self._max_iter,\n                abs(score_val),\n            )\n\n        return rho\n\n    # ------------------------------------------------------------------\n    # Solver: direct log-likelihood via Brent's bounded method\n    # ------------------------------------------------------------------\n\n    def _polychoric_brent(\n        self,\n        n_rs: np.ndarray,\n        tx: np.ndarray,\n        ty: np.ndarray,\n        ux: np.ndarray,\n        uy: np.ndarray,\n    ) -&gt; float:\n        r\"\"\"Maximise $\\\\ell(\\\\rho)$ directly via ``minimize_scalar`` (Brent bounded).\n\n        Each function evaluation costs one :func:`_pi_rs` call per cell.\n        No derivative information is used; convergence is super-linear.\n        Near-zero cell probabilities are floored at *_CELL_FLOOR* so that\n        empty cells never produce ``-inf`` contributions.\n        \"\"\"\n        bound = self._max_cor\n\n        def neg_log_likelihood(rho: float) -&gt; float:\n            total = 0.0\n            for i in range(len(ux)):\n                for j in range(len(uy)):\n                    if n_rs[i, j] == 0:\n                        continue\n                    lower = (float(tx[i]), float(ty[j]))\n                    upper = (float(tx[i + 1]), float(ty[j + 1]))\n                    p = max(_pi_rs(lower=lower, upper=upper, corr=rho), _CELL_FLOOR)\n                    total += n_rs[i, j] * np.log(p)\n            return -total\n\n        result = minimize_scalar(neg_log_likelihood, bounds=(-bound, bound), method=\"bounded\")\n        return float(result.x)\n</code></pre> <p>               Bases: <code>CorrelationMeasure</code></p> <p>Ad-hoc polyserial correlation between one continuous and one ordinal variable.</p> <p>The estimator applies the nonparanormal (rank-based) transformation to the continuous variable and uses a closed-form correction factor derived from the ordinal thresholds to approximate the underlying latent correlation.</p> <p>Parameters:</p> Name Type Description Default <code>max_cor</code> <code>float</code> <p>Absolute upper bound for the estimated correlation. Defaults to 0.9999.</p> <code>0.9999</code> <code>n_levels_threshold</code> <code>int</code> <p>Variables with fewer unique values than this threshold are treated as ordinal.  Defaults to 20.</p> <code>20</code> <p>Example::</p> <pre><code>rho = PolyserialCorrelation().fit(x_cont, y_ord).correlation\n</code></pre> Source code in <code>hume/correlation.py</code> <pre><code>class PolyserialCorrelation(CorrelationMeasure):\n    \"\"\"Ad-hoc polyserial correlation between one continuous and one ordinal variable.\n\n    The estimator applies the nonparanormal (rank-based) transformation to the\n    continuous variable and uses a closed-form correction factor derived from\n    the ordinal thresholds to approximate the underlying latent correlation.\n\n    Args:\n        max_cor: Absolute upper bound for the estimated correlation.\n            Defaults to 0.9999.\n        n_levels_threshold: Variables with fewer unique values than this\n            threshold are treated as ordinal.  Defaults to 20.\n\n    Example::\n\n        rho = PolyserialCorrelation().fit(x_cont, y_ord).correlation\n    \"\"\"\n\n    def __init__(\n        self,\n        max_cor: float = 0.9999,\n        n_levels_threshold: int = 20,\n    ) -&gt; None:\n        \"\"\"Inits polyserial correlation class.\n\n        Args:\n            max_cor (float, optional): Defaults to 0.9999.\n            n_levels_threshold (int, optional): Until what level set to treat a variable as ordinal. Defaults to 20.\n\n        Raises:\n            ValueError: _description_\n        \"\"\"\n        super().__init__(max_cor=max_cor)\n        if n_levels_threshold &lt; 2:\n            raise ValueError(\"`n_levels_threshold` must be \u2265 2.\")\n        self._n_levels_threshold = n_levels_threshold\n\n    def fit(self, x: np.ndarray, y: np.ndarray) -&gt; PolyserialCorrelation:\n        \"\"\"Fit the polyserial correlation model.\n\n        The method automatically identifies which argument is the continuous\n        variable and which is the ordinal variable based on the number of\n        unique values.\n\n        Args:\n            x: One variable (continuous or ordinal).\n            y: The other variable (ordinal or continuous).\n\n        Returns:\n            *self*\n\n        Raises:\n            ValueError: On invalid inputs or if both variables appear to be\n                continuous (use a Spearman/NPP estimator instead) or if both\n                appear to be ordinal (use :class:`PolychoricCorrelation`\n                instead).\n        \"\"\"\n        x_arr, y_arr = self._prepare(x, y)\n\n        x_is_ord = len(np.unique(x_arr)) &lt; self._n_levels_threshold\n        y_is_ord = len(np.unique(y_arr)) &lt; self._n_levels_threshold\n\n        if not x_is_ord and not y_is_ord:\n            raise ValueError(\n                \"Both variables appear continuous (\u2265 n_levels_threshold unique values). \"\n                \"Use a Spearman or nonparanormal estimator instead.\"\n            )\n        if x_is_ord and y_is_ord:\n            raise ValueError(\n                \"Both variables appear ordinal (&lt; n_levels_threshold unique values). Use PolychoricCorrelation instead.\"\n            )\n\n        if x_is_ord:\n            cont_arr, ord_arr = y_arr, x_arr\n            cont_name, ord_name = \"y\", \"x\"\n        else:\n            cont_arr, ord_arr = x_arr, y_arr\n            cont_name, ord_name = \"x\", \"y\"\n\n        _validate_continuous(cont_arr, cont_name)\n        _validate_ordinal(ord_arr, ord_name)\n\n        self._correlation = self._clip(self._polyserial(cont_arr, ord_arr))\n        return self\n\n    # ------------------------------------------------------------------\n    # Implementation\n    # ------------------------------------------------------------------\n\n    def _polyserial(self, cont: np.ndarray, disc: np.ndarray) -&gt; float:\n        unique_vals, _ = np.unique(disc, return_counts=True)\n        threshold_estimate = _thresholds(disc)\n\n        values = np.sort(unique_vals.astype(float))\n        interior_thresholds = threshold_estimate[1:-1]\n        value_diff = np.diff(values)\n        lambda_val: float = float(np.sum(stats.norm.pdf(interior_thresholds) * value_diff))\n\n        if lambda_val == 0:\n            raise ValueError(\n                \"Denominator \u03bb in ad-hoc polyserial estimator is zero. \"\n                \"This can happen when ordinal categories are far apart in \"\n                \"probability space.  Consider recoding the ordinal variable.\"\n            )\n\n        s_disc = float(np.std(disc.astype(float), ddof=1))\n        r = _npn_pearson(cont, disc)\n        return r * s_disc / lambda_val\n</code></pre> <p>Spearman's rank correlation coefficient.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>First numeric array.</p> required <code>y</code> <code>ndarray</code> <p>Second numeric array (same length as x).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Spearman's \u03c1 in [\u22121, 1].</p> Source code in <code>hume/correlation.py</code> <pre><code>def spearman(x: np.ndarray, y: np.ndarray) -&gt; float:\n    \"\"\"Spearman's rank correlation coefficient.\n\n    Args:\n        x: First numeric array.\n        y: Second numeric array (same length as *x*).\n\n    Returns:\n        Spearman's \u03c1 in [\u22121, 1].\n    \"\"\"\n    x_arr, y_arr = _to_array(x), _to_array(y)\n    _validate_pair(x_arr, y_arr)\n    rho, _ = stats.spearmanr(x_arr, y_arr)  # pyright: ignore[reportArgumentType]\n    return float(rho)\n</code></pre> <p>Winsorized nonparanormal transformation.</p> <p>Implements the estimator from Liu, Lafferty &amp; Wasserman (2009):  each observation is mapped to its normal score and the result is scaled to unit variance.  Extreme ranks are Winsorized to avoid \u00b1\u221e.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>A 1-D numeric array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Transformed array of the same length, scaled to unit variance.</p> Source code in <code>hume/correlation.py</code> <pre><code>def f_hat(x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Winsorized nonparanormal transformation.\n\n    Implements the estimator from Liu, Lafferty &amp; Wasserman (2009):  each\n    observation is mapped to its normal score and the result is scaled to\n    unit variance.  Extreme ranks are Winsorized to avoid \u00b1\u221e.\n\n    Args:\n        x: A 1-D numeric array.\n\n    Returns:\n        Transformed array of the same length, scaled to unit variance.\n    \"\"\"\n    x_arr = _to_array(x)\n    if x_arr.size &lt; 2:\n        raise ValueError(\"f_hat requires at least 2 observations.\")\n    return _f_hat(x_arr)\n</code></pre> <p>Nonparanormal product-moment correlation.</p> <p>Parameters:</p> Name Type Description Default <code>cont</code> <code>ndarray</code> <p>Continuous numeric array.</p> required <code>disc</code> <code>ndarray</code> <p>Discrete/ordinal array.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Correlation coefficient in [\u22121, 1].</p> Source code in <code>hume/correlation.py</code> <pre><code>def npn_pearson(cont: np.ndarray, disc: np.ndarray) -&gt; float:\n    \"\"\"Nonparanormal product-moment correlation.\n\n    Args:\n        cont: Continuous numeric array.\n        disc: Discrete/ordinal array.\n\n    Returns:\n        Correlation coefficient in [\u22121, 1].\n    \"\"\"\n    cont_arr, disc_arr = _to_array(cont), _to_array(disc)\n    _validate_pair(cont_arr, disc_arr)\n    return _npn_pearson(cont_arr, disc_arr)\n</code></pre> <p>Convenience dispatcher for mixed-type correlation estimation.</p> <p>Selects the appropriate estimator based on the number of unique values:</p> <ul> <li>Both continuous \u2192 nonparanormal Spearman sin-transformation.</li> <li>Both ordinal \u2192 :class:<code>PolychoricCorrelation</code>.</li> <li>Mixed \u2192 :class:<code>PolyserialCorrelation</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>First array (discrete or continuous).</p> required <code>y</code> <code>ndarray</code> <p>Second array (discrete or continuous).</p> required <code>max_cor</code> <code>float</code> <p>Maximum allowed absolute correlation; clips to \u00b1max_cor.</p> <code>0.9999</code> <code>n_levels_threshold</code> <code>int</code> <p>Unique-value count below which a variable is treated as ordinal.</p> <code>20</code> <code>verbose</code> <code>bool</code> <p>Emit an :mod:<code>logging</code> info message describing the chosen estimator.</p> <code>False</code> <p>Returns:</p> Type Description <code>float</code> <p>Correlation estimate in [\u22121, 1].</p> Source code in <code>hume/correlation.py</code> <pre><code>def adhoc_polyserial(\n    x: np.ndarray,\n    y: np.ndarray,\n    *,\n    max_cor: float = 0.9999,\n    n_levels_threshold: int = 20,\n    verbose: bool = False,\n) -&gt; float:\n    \"\"\"Convenience dispatcher for mixed-type correlation estimation.\n\n    Selects the appropriate estimator based on the number of unique values:\n\n    * Both continuous \u2192 nonparanormal Spearman sin-transformation.\n    * Both ordinal \u2192 :class:`PolychoricCorrelation`.\n    * Mixed \u2192 :class:`PolyserialCorrelation`.\n\n    Args:\n        x: First array (discrete or continuous).\n        y: Second array (discrete or continuous).\n        max_cor: Maximum allowed absolute correlation; clips to \u00b1*max_cor*.\n        n_levels_threshold: Unique-value count below which a variable is\n            treated as ordinal.\n        verbose: Emit an :mod:`logging` info message describing the chosen\n            estimator.\n\n    Returns:\n        Correlation estimate in [\u22121, 1].\n    \"\"\"\n    x_arr, y_arr = _to_array(x), _to_array(y)\n    _validate_pair(x_arr, y_arr)\n\n    n_unique_x = len(np.unique(x_arr))\n    n_unique_y = len(np.unique(y_arr))\n    x_is_discrete = n_unique_x &lt; n_levels_threshold\n    y_is_discrete = n_unique_y &lt; n_levels_threshold\n\n    if not x_is_discrete and not y_is_discrete:\n        if verbose:\n            logger.info(\"Both variables continuous \u2014 using nonparanormal Spearman.\")\n        rho = spearman(x_arr, y_arr)\n        return float(np.clip(2 * np.sin(np.pi / 6 * rho), -max_cor, max_cor))\n\n    if x_is_discrete and y_is_discrete:\n        if verbose:\n            logger.info(\"Both variables ordinal \u2014 using polychoric correlation.\")\n        return PolychoricCorrelation(max_cor=max_cor).fit(x_arr, y_arr).correlation\n\n    if verbose:\n        logger.info(\"Mixed pair \u2014 using ad-hoc polyserial correlation.\")\n    return PolyserialCorrelation(max_cor=max_cor, n_levels_threshold=n_levels_threshold).fit(x_arr, y_arr).correlation\n</code></pre>"},{"location":"reference/#hume.correlation.PolychoricCorrelation.__init__","title":"<code>__init__(max_cor=0.9999, solver='brent', max_iter=100, tol=1e-10)</code>","text":"<p>Initialise the polychoric correlation estimator.</p> <p>Parameters:</p> Name Type Description Default <code>max_cor</code> <code>float</code> <p>Absolute upper bound for the estimated correlation. Defaults to 0.9999.</p> <code>0.9999</code> <code>solver</code> <code>Literal['newton', 'brent']</code> <p>Optimisation strategy.  <code>\"brent\"</code> (default) is faster for variables with 4 or more ordinal categories. <code>\"newton\"</code> (Fisher scoring) can be ~2\u00d7 faster for binary variables but slows down as category count grows.</p> <code>'brent'</code> <code>max_iter</code> <code>int</code> <p>Maximum Fisher-scoring iterations; ignored when <code>solver=\"brent\"</code>.  Defaults to 100.</p> <code>100</code> <code>tol</code> <code>float</code> <p>Convergence tolerance on the absolute score value and step size; ignored when <code>solver=\"brent\"</code>.  Defaults to 1e-10.</p> <code>1e-10</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If solver is not <code>\"newton\"</code> or <code>\"brent\"</code>.</p> Source code in <code>hume/correlation.py</code> <pre><code>def __init__(\n    self,\n    max_cor: float = 0.9999,\n    solver: Literal[\"newton\", \"brent\"] = \"brent\",\n    max_iter: int = 100,\n    tol: float = 1e-10,\n) -&gt; None:\n    \"\"\"Initialise the polychoric correlation estimator.\n\n    Args:\n        max_cor: Absolute upper bound for the estimated correlation.\n            Defaults to 0.9999.\n        solver: Optimisation strategy.  ``\"brent\"`` (default) is faster\n            for variables with 4 or more ordinal categories.\n            ``\"newton\"`` (Fisher scoring) can be ~2\u00d7 faster for binary\n            variables but slows down as category count grows.\n        max_iter: Maximum Fisher-scoring iterations; ignored when\n            ``solver=\"brent\"``.  Defaults to 100.\n        tol: Convergence tolerance on the absolute score value and step\n            size; ignored when ``solver=\"brent\"``.  Defaults to 1e-10.\n\n    Raises:\n        ValueError: If *solver* is not ``\"newton\"`` or ``\"brent\"``.\n    \"\"\"\n    super().__init__(max_cor=max_cor)\n    if solver not in {\"newton\", \"brent\"}:\n        raise ValueError(f\"`solver` must be 'newton' or 'brent', got '{solver}'.\")\n    self._solver = solver\n    self._max_iter = max_iter\n    self._tol = tol\n</code></pre>"},{"location":"reference/#hume.correlation.PolychoricCorrelation.fit","title":"<code>fit(x, y)</code>","text":"<p>Fit the polychoric correlation model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>First ordinal variable (integer-valued or small number of distinct float levels).</p> required <code>y</code> <code>ndarray</code> <p>Second ordinal variable.</p> required <p>Returns:</p> Type Description <code>PolychoricCorrelation</code> <p>self</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>On invalid or incompatible inputs.</p> <code>RuntimeError</code> <p>If the solver cannot converge.</p> Source code in <code>hume/correlation.py</code> <pre><code>def fit(self, x: np.ndarray, y: np.ndarray) -&gt; PolychoricCorrelation:\n    \"\"\"Fit the polychoric correlation model.\n\n    Args:\n        x: First ordinal variable (integer-valued or small number of\n            distinct float levels).\n        y: Second ordinal variable.\n\n    Returns:\n        *self*\n\n    Raises:\n        ValueError: On invalid or incompatible inputs.\n        RuntimeError: If the solver cannot converge.\n    \"\"\"\n    x_arr, y_arr = self._prepare(x, y)\n    _validate_ordinal(x_arr, \"x\")\n    _validate_ordinal(y_arr, \"y\")\n\n    self._correlation = self._clip(self._polychoric(x_arr, y_arr))\n    return self\n</code></pre>"},{"location":"reference/#hume.correlation.PolyserialCorrelation.__init__","title":"<code>__init__(max_cor=0.9999, n_levels_threshold=20)</code>","text":"<p>Inits polyserial correlation class.</p> <p>Parameters:</p> Name Type Description Default <code>max_cor</code> <code>float</code> <p>Defaults to 0.9999.</p> <code>0.9999</code> <code>n_levels_threshold</code> <code>int</code> <p>Until what level set to treat a variable as ordinal. Defaults to 20.</p> <code>20</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>description</p> Source code in <code>hume/correlation.py</code> <pre><code>def __init__(\n    self,\n    max_cor: float = 0.9999,\n    n_levels_threshold: int = 20,\n) -&gt; None:\n    \"\"\"Inits polyserial correlation class.\n\n    Args:\n        max_cor (float, optional): Defaults to 0.9999.\n        n_levels_threshold (int, optional): Until what level set to treat a variable as ordinal. Defaults to 20.\n\n    Raises:\n        ValueError: _description_\n    \"\"\"\n    super().__init__(max_cor=max_cor)\n    if n_levels_threshold &lt; 2:\n        raise ValueError(\"`n_levels_threshold` must be \u2265 2.\")\n    self._n_levels_threshold = n_levels_threshold\n</code></pre>"},{"location":"reference/#hume.correlation.PolyserialCorrelation.fit","title":"<code>fit(x, y)</code>","text":"<p>Fit the polyserial correlation model.</p> <p>The method automatically identifies which argument is the continuous variable and which is the ordinal variable based on the number of unique values.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>One variable (continuous or ordinal).</p> required <code>y</code> <code>ndarray</code> <p>The other variable (ordinal or continuous).</p> required <p>Returns:</p> Type Description <code>PolyserialCorrelation</code> <p>self</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>On invalid inputs or if both variables appear to be continuous (use a Spearman/NPP estimator instead) or if both appear to be ordinal (use :class:<code>PolychoricCorrelation</code> instead).</p> Source code in <code>hume/correlation.py</code> <pre><code>def fit(self, x: np.ndarray, y: np.ndarray) -&gt; PolyserialCorrelation:\n    \"\"\"Fit the polyserial correlation model.\n\n    The method automatically identifies which argument is the continuous\n    variable and which is the ordinal variable based on the number of\n    unique values.\n\n    Args:\n        x: One variable (continuous or ordinal).\n        y: The other variable (ordinal or continuous).\n\n    Returns:\n        *self*\n\n    Raises:\n        ValueError: On invalid inputs or if both variables appear to be\n            continuous (use a Spearman/NPP estimator instead) or if both\n            appear to be ordinal (use :class:`PolychoricCorrelation`\n            instead).\n    \"\"\"\n    x_arr, y_arr = self._prepare(x, y)\n\n    x_is_ord = len(np.unique(x_arr)) &lt; self._n_levels_threshold\n    y_is_ord = len(np.unique(y_arr)) &lt; self._n_levels_threshold\n\n    if not x_is_ord and not y_is_ord:\n        raise ValueError(\n            \"Both variables appear continuous (\u2265 n_levels_threshold unique values). \"\n            \"Use a Spearman or nonparanormal estimator instead.\"\n        )\n    if x_is_ord and y_is_ord:\n        raise ValueError(\n            \"Both variables appear ordinal (&lt; n_levels_threshold unique values). Use PolychoricCorrelation instead.\"\n        )\n\n    if x_is_ord:\n        cont_arr, ord_arr = y_arr, x_arr\n        cont_name, ord_name = \"y\", \"x\"\n    else:\n        cont_arr, ord_arr = x_arr, y_arr\n        cont_name, ord_name = \"x\", \"y\"\n\n    _validate_continuous(cont_arr, cont_name)\n    _validate_ordinal(ord_arr, ord_name)\n\n    self._correlation = self._clip(self._polyserial(cont_arr, ord_arr))\n    return self\n</code></pre>"},{"location":"reference/#legacy-functions","title":"Legacy Functions","text":"<p>Estimate a mixed graphical model (backward-compatible wrapper).</p> <p>.. deprecated::     Prefer :class:<code>MixedGraphicalLasso</code> directly.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | NDArray[Any]</code> <p>Data matrix <code>(n_samples, n_features)</code>.</p> required <code>verbose</code> <code>bool</code> <p>Emit logging warnings.</p> <code>True</code> <code>n_lambdas</code> <code>int</code> <p>Length of the regularisation path.</p> <code>50</code> <code>param</code> <code>float</code> <p>eBIC dimensionality penalty weight (gamma).</p> <code>0.1</code> <code>feature_names</code> <code>list[str] | None</code> <p>Override column names.</p> <code>None</code> <code>n_levels_threshold</code> <code>int</code> <p>Ordinal detection threshold.</p> <code>20</code> <p>Returns:</p> Type Description <code>MixedGraphResult</code> <p>class:<code>MixedGraphResult</code></p> Source code in <code>hume/estimation.py</code> <pre><code>def mixed_graph_nonpara(\n    data: pd.DataFrame | NDArray[Any],\n    *,\n    verbose: bool = True,\n    n_lambdas: int = 50,\n    param: float = 0.1,\n    feature_names: list[str] | None = None,\n    n_levels_threshold: int = 20,\n) -&gt; MixedGraphResult:\n    \"\"\"Estimate a mixed graphical model (backward-compatible wrapper).\n\n    .. deprecated::\n        Prefer :class:`MixedGraphicalLasso` directly.\n\n    Args:\n        data: Data matrix ``(n_samples, n_features)``.\n        verbose: Emit logging warnings.\n        n_lambdas: Length of the regularisation path.\n        param: eBIC dimensionality penalty weight (gamma).\n        feature_names: Override column names.\n        n_levels_threshold: Ordinal detection threshold.\n\n    Returns:\n        :class:`MixedGraphResult`\n    \"\"\"\n    return _legacy_fit(\n        data,\n        verbose=verbose,\n        n_lambdas=n_lambdas,\n        param=param,\n        feature_names=feature_names,\n        n_levels_threshold=n_levels_threshold,\n    )\n</code></pre> <p>Estimate a mixed graphical model (backward-compatible wrapper).</p> <p>.. deprecated::     Prefer :class:<code>MixedGraphicalLasso</code> directly.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | NDArray[Any]</code> <p>Data matrix <code>(n_samples, n_features)</code>.</p> required <code>verbose</code> <code>bool</code> <p>Emit logging warnings.</p> <code>True</code> <code>n_lambdas</code> <code>int</code> <p>Length of the regularisation path.</p> <code>50</code> <code>param</code> <code>float</code> <p>eBIC dimensionality penalty weight (gamma).</p> <code>0.1</code> <code>feature_names</code> <code>list[str] | None</code> <p>Override column names.</p> <code>None</code> <code>n_levels_threshold</code> <code>int</code> <p>Ordinal detection threshold.</p> <code>20</code> <p>Returns:</p> Type Description <code>MixedGraphResult</code> <p>class:<code>MixedGraphResult</code></p> Source code in <code>hume/estimation.py</code> <pre><code>def mixed_graph_gauss(\n    data: pd.DataFrame | NDArray[Any],\n    *,\n    verbose: bool = True,\n    n_lambdas: int = 50,\n    param: float = 0.1,\n    feature_names: list[str] | None = None,\n    n_levels_threshold: int = 20,\n) -&gt; MixedGraphResult:\n    \"\"\"Estimate a mixed graphical model (backward-compatible wrapper).\n\n    .. deprecated::\n        Prefer :class:`MixedGraphicalLasso` directly.\n\n    Args:\n        data: Data matrix ``(n_samples, n_features)``.\n        verbose: Emit logging warnings.\n        n_lambdas: Length of the regularisation path.\n        param: eBIC dimensionality penalty weight (gamma).\n        feature_names: Override column names.\n        n_levels_threshold: Ordinal detection threshold.\n\n    Returns:\n        :class:`MixedGraphResult`\n    \"\"\"\n    return _legacy_fit(\n        data,\n        verbose=verbose,\n        n_lambdas=n_lambdas,\n        param=param,\n        feature_names=feature_names,\n        n_levels_threshold=n_levels_threshold,\n    )\n</code></pre> <p>Legacy result container kept for backward compatibility.</p> <p>New code should use :class:<code>MixedGraphicalLasso</code> directly and access results via its attributes.</p> <p>Attributes:</p> Name Type Description <code>precision_matrix</code> <code>NDArray[Any]</code> <p>Estimated partial correlation matrix as a numpy array.</p> <code>adjacency_matrix</code> <code>NDArray[bool_]</code> <p>Boolean adjacency matrix (True = edge present).</p> <code>correlation_matrix</code> <code>NDArray[Any]</code> <p>Sample correlation matrix fed to graphical lasso.</p> <code>n_edges</code> <code>int</code> <p>Number of edges in the estimated graph.</p> <code>max_degree</code> <code>int</code> <p>Largest node degree.</p> <code>initial_mat_singular</code> <code>bool</code> <p>Whether the correlation matrix needed PD projection.</p> <code>feature_names</code> <code>list[str] | None</code> <p>Variable names (None if not provided).</p> Source code in <code>hume/estimation.py</code> <pre><code>@dataclass\nclass MixedGraphResult:\n    \"\"\"Legacy result container kept for backward compatibility.\n\n    New code should use :class:`MixedGraphicalLasso` directly and access\n    results via its attributes.\n\n    Attributes:\n        precision_matrix: Estimated partial correlation matrix as a numpy array.\n        adjacency_matrix: Boolean adjacency matrix (True = edge present).\n        correlation_matrix: Sample correlation matrix fed to graphical lasso.\n        n_edges: Number of edges in the estimated graph.\n        max_degree: Largest node degree.\n        initial_mat_singular: Whether the correlation matrix needed PD projection.\n        feature_names: Variable names (None if not provided).\n    \"\"\"\n\n    precision_matrix: NDArray[Any]\n    adjacency_matrix: NDArray[np.bool_]\n    correlation_matrix: NDArray[Any]\n    n_edges: int\n    max_degree: int\n    initial_mat_singular: bool\n    feature_names: list[str] | None = None\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return string representation.\"\"\"\n        n_nodes = self.precision_matrix.shape[0]\n        return f\"MixedGraphResult(n_nodes={n_nodes}, n_edges={self.n_edges}, max_degree={self.max_degree})\"\n</code></pre> <p>Calculate number of edges given a precision matrix.</p> <p>Thin wrapper around :func:<code>_edgenumber</code> kept for backward compatibility.</p> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>NDArray[Any]</code> <p>Square precision or partial-correlation matrix.</p> required <code>cut</code> <code>float</code> <p>Entries with |value| &lt;= cut are treated as zero.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>int</code> <p>Number of edges (lower-triangular non-zeros).</p> Source code in <code>hume/estimation.py</code> <pre><code>def edgenumber(precision: NDArray[Any], *, cut: float = 0.0) -&gt; int:\n    \"\"\"Calculate number of edges given a precision matrix.\n\n    Thin wrapper around :func:`_edgenumber` kept for backward compatibility.\n\n    Args:\n        precision: Square precision or partial-correlation matrix.\n        cut: Entries with |value| &lt;= *cut* are treated as zero.\n\n    Returns:\n        Number of edges (lower-triangular non-zeros).\n    \"\"\"\n    return _edgenumber(precision, cut=cut)\n</code></pre>"},{"location":"reference/#hume.estimation.MixedGraphResult.__repr__","title":"<code>__repr__()</code>","text":"<p>Return string representation.</p> Source code in <code>hume/estimation.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return string representation.\"\"\"\n    n_nodes = self.precision_matrix.shape[0]\n    return f\"MixedGraphResult(n_nodes={n_nodes}, n_edges={self.n_edges}, max_degree={self.max_degree})\"\n</code></pre>"}]}